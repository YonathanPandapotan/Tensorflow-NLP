{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Latihan Dicoding - NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPHdRcszOISKMLPEc0iblSY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YonathanPandapotan/Tensorflow-NLP/blob/master/Latihan_Dicoding_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BpQrIeI5-K4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Machine Learning ini akan membaca datasets dan menentukan jenis aplikasi\n",
        "# yang terdapat pada Windows Store berdasarkan nama aplikasi tersebut\n",
        "# Langkah jalan aplikasi\n",
        "\"\"\"\n",
        "1. Baca datasets terlebih dahulu\n",
        "2. Kemudian persiapkan library NLTK dan STOPWORDS\n",
        "3. Berikutnya kita lakukan one-hot-encoding pada Category\n",
        "4. Membagi dataframe menjadi value dan label\n",
        "5. Mengganti setiap Stopwords yang ada pada text\n",
        "6. Train-test-split\n",
        "7. Buat Tokenizer untuk data training dan validasi\n",
        "8. Buat model (sequential)\n",
        "9. Membuat callback\n",
        "10. Kemudian latih model kita\n",
        "11. Terakhir tunjukkan plotting accuracy dan loss - training dan test\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqg37pEm6sEw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "716d3649-afd1-4ae7-e51f-73a10caf200f"
      },
      "source": [
        "import pandas as pd\n",
        "datasets = pd.read_csv('bbc-text.csv')\n",
        "print(datasets.tail())\n",
        "print('\\n')\n",
        "print(\"Size dari datasets \", len(datasets))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      category                                               text\n",
            "1833  business  us gives foreign firms extra time foreign firm...\n",
            "1834  politics  school sport  is back   says pm tony blair has...\n",
            "1835     sport  henman overcomes rival rusedski tim henman sav...\n",
            "1836     sport  saint-andre anger at absent stars sale sharks ...\n",
            "1837  politics  watchdog probes e-mail deletions the informati...\n",
            "\n",
            "\n",
            "Size dari datasets  1838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3trsfNpRiYl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b2e5b235-24b0-4060-edfe-677082af3a53"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "STOPWORDS = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xz3ePBQR7wSJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "e6f5272e-078c-42ae-8b80-52245534906b"
      },
      "source": [
        "category = pd.get_dummies(datasets.category)\n",
        "dataframe_baru = pd.concat([datasets, category], axis=1)\n",
        "dataframe_baru = dataframe_baru.drop(columns='category')\n",
        "dataframe_baru"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>business</th>\n",
              "      <th>entertainment</th>\n",
              "      <th>politics</th>\n",
              "      <th>sport</th>\n",
              "      <th>tech</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1833</th>\n",
              "      <td>us gives foreign firms extra time foreign firm...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1834</th>\n",
              "      <td>school sport  is back   says pm tony blair has...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1835</th>\n",
              "      <td>henman overcomes rival rusedski tim henman sav...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1836</th>\n",
              "      <td>saint-andre anger at absent stars sale sharks ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1837</th>\n",
              "      <td>watchdog probes e-mail deletions the informati...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1838 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  business  ...  sport  tech\n",
              "0     tv future in the hands of viewers with home th...         0  ...      0     1\n",
              "1     worldcom boss  left books alone  former worldc...         1  ...      0     0\n",
              "2     tigers wary of farrell  gamble  leicester say ...         0  ...      1     0\n",
              "3     yeading face newcastle in fa cup premiership s...         0  ...      1     0\n",
              "4     ocean s twelve raids box office ocean s twelve...         0  ...      0     0\n",
              "...                                                 ...       ...  ...    ...   ...\n",
              "1833  us gives foreign firms extra time foreign firm...         1  ...      0     0\n",
              "1834  school sport  is back   says pm tony blair has...         0  ...      0     0\n",
              "1835  henman overcomes rival rusedski tim henman sav...         0  ...      1     0\n",
              "1836  saint-andre anger at absent stars sale sharks ...         0  ...      1     0\n",
              "1837  watchdog probes e-mail deletions the informati...         0  ...      0     0\n",
              "\n",
              "[1838 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QloEGd9i8Qvp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "2b012609-d994-4e91-bc69-97cacfb1e665"
      },
      "source": [
        "tulisan_text = dataframe_baru['text'].values\n",
        "category = dataframe_baru[['business',\n",
        "                          'entertainment',\n",
        "                          'politics',\n",
        "                          'sport',\n",
        "                          'tech']].values\n",
        "tulisan_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['tv future in the hands of viewers with home theatre systems  plasma high-definition tvs  and digital video recorders moving into the living room  the way people watch tv will be radically different in five years  time.  that is according to an expert panel which gathered at the annual consumer electronics show in las vegas to discuss how these new technologies will impact one of our favourite pastimes. with the us leading the trend  programmes and other content will be delivered to viewers via home networks  through cable  satellite  telecoms companies  and broadband service providers to front rooms and portable devices.  one of the most talked-about technologies of ces has been digital and personal video recorders (dvr and pvr). these set-top boxes  like the us s tivo and the uk s sky+ system  allow people to record  store  play  pause and forward wind tv programmes when they want.  essentially  the technology allows for much more personalised tv. they are also being built-in to high-definition tv sets  which are big business in japan and the us  but slower to take off in europe because of the lack of high-definition programming. not only can people forward wind through adverts  they can also forget about abiding by network and channel schedules  putting together their own a-la-carte entertainment. but some us networks and cable and satellite companies are worried about what it means for them in terms of advertising revenues as well as  brand identity  and viewer loyalty to channels. although the us leads in this technology at the moment  it is also a concern that is being raised in europe  particularly with the growing uptake of services like sky+.  what happens here today  we will see in nine months to a years  time in the uk   adam hume  the bbc broadcast s futurologist told the bbc news website. for the likes of the bbc  there are no issues of lost advertising revenue yet. it is a more pressing issue at the moment for commercial uk broadcasters  but brand loyalty is important for everyone.  we will be talking more about content brands rather than network brands   said tim hanlon  from brand communications firm starcom mediavest.  the reality is that with broadband connections  anybody can be the producer of content.  he added:  the challenge now is that it is hard to promote a programme with so much choice.   what this means  said stacey jolna  senior vice president of tv guide tv group  is that the way people find the content they want to watch has to be simplified for tv viewers. it means that networks  in us terms  or channels could take a leaf out of google s book and be the search engine of the future  instead of the scheduler to help people find what they want to watch. this kind of channel model might work for the younger ipod generation which is used to taking control of their gadgets and what they play on them. but it might not suit everyone  the panel recognised. older generations are more comfortable with familiar schedules and channel brands because they know what they are getting. they perhaps do not want so much of the choice put into their hands  mr hanlon suggested.  on the other end  you have the kids just out of diapers who are pushing buttons already - everything is possible and available to them   said mr hanlon.  ultimately  the consumer will tell the market they want.   of the 50 000 new gadgets and technologies being showcased at ces  many of them are about enhancing the tv-watching experience. high-definition tv sets are everywhere and many new models of lcd (liquid crystal display) tvs have been launched with dvr capability built into them  instead of being external boxes. one such example launched at the show is humax s 26-inch lcd tv with an 80-hour tivo dvr and dvd recorder. one of the us s biggest satellite tv companies  directtv  has even launched its own branded dvr at the show with 100-hours of recording capability  instant replay  and a search function. the set can pause and rewind tv for up to 90 hours. and microsoft chief bill gates announced in his pre-show keynote speech a partnership with tivo  called tivotogo  which means people can play recorded programmes on windows pcs and mobile devices. all these reflect the increasing trend of freeing up multimedia so that people can watch what they want  when they want.',\n",
              "       'worldcom boss  left books alone  former worldcom boss bernie ebbers  who is accused of overseeing an $11bn (£5.8bn) fraud  never made accounting decisions  a witness has told jurors.  david myers made the comments under questioning by defence lawyers who have been arguing that mr ebbers was not responsible for worldcom s problems. the phone company collapsed in 2002 and prosecutors claim that losses were hidden to protect the firm s shares. mr myers has already pleaded guilty to fraud and is assisting prosecutors.  on monday  defence lawyer reid weingarten tried to distance his client from the allegations. during cross examination  he asked mr myers if he ever knew mr ebbers  make an accounting decision  .  not that i am aware of   mr myers replied.  did you ever know mr ebbers to make an accounting entry into worldcom books   mr weingarten pressed.  no   replied the witness. mr myers has admitted that he ordered false accounting entries at the request of former worldcom chief financial officer scott sullivan. defence lawyers have been trying to paint mr sullivan  who has admitted fraud and will testify later in the trial  as the mastermind behind worldcom s accounting house of cards.  mr ebbers  team  meanwhile  are looking to portray him as an affable boss  who by his own admission is more pe graduate than economist. whatever his abilities  mr ebbers transformed worldcom from a relative unknown into a $160bn telecoms giant and investor darling of the late 1990s. worldcom s problems mounted  however  as competition increased and the telecoms boom petered out. when the firm finally collapsed  shareholders lost about $180bn and 20 000 workers lost their jobs. mr ebbers  trial is expected to last two months and if found guilty the former ceo faces a substantial jail sentence. he has firmly declared his innocence.',\n",
              "       'tigers wary of farrell  gamble  leicester say they will not be rushed into making a bid for andy farrell should the great britain rugby league captain decide to switch codes.   we and anybody else involved in the process are still some way away from going to the next stage   tigers boss john wells told bbc radio leicester.  at the moment  there are still a lot of unknowns about andy farrell  not least his medical situation.  whoever does take him on is going to take a big  big gamble.  farrell  who has had persistent knee problems  had an operation on his knee five weeks ago and is expected to be out for another three months. leicester and saracens are believed to head the list of rugby union clubs interested in signing farrell if he decides to move to the 15-man game.  if he does move across to union  wells believes he would better off playing in the backs  at least initially.  i m sure he could make the step between league and union by being involved in the centre   said wells.  i think england would prefer him to progress to a position in the back row where they can make use of some of his rugby league skills within the forwards.  the jury is out on whether he can cross that divide.  at this club  the balance will have to be struck between the cost of that gamble and the option of bringing in a ready-made replacement.',\n",
              "       ...,\n",
              "       'henman overcomes rival rusedski tim henman saved a match point before fighting back to defeat british rival greg rusedski 4-6 7-6 (8-6) 6-4 at the dubai tennis championships on tuesday.  world number 46 rusedski broke in the ninth game to take a tight opening set. rusedski had match point at 6-5 in the second set tie-break after henman double-faulted  but missed his chance and henman rallied to clinch the set. the british number one then showed his superior strength to take the decider and earn his sixth win over rusedski. serve was held by both players with few alarms until the seventh game of the final set  when rusedski s wild volley gave henman a vital break. a furious rusedski slammed his racket onto the ground in disgust and was warned by the umpire.  henman  seeded three  then held his serve comfortably thanks to four serve-and-volley winners to take a clear 5-3 lead. rusedski won his service game but henman took the first of his three match points with a service winner to secure his place in the second round at dubai for the first time in three years. it was the first match between the pair for three years - henman last lost to rusedski six years ago - and lasted two hours and 40 minutes. the pair are now likely to only face each other on court as rivals - rather than as team-mates - after henman decided to retire from davis cup tennis leaving rusedski to lead the team out against israel on 4-6 march. henman  who now faces russian igor andreev in the last 16  admitted afterwards it was difficult coming up against his compatriot on a fast surface.  you just take it point by point when you re fighting to stay in the match   he said.  i had to keep playing aggressively and competing to get a chance.  i now have to recover in time for the next match because the body doesn t recover as quick as it used to  especially after two hours and 40 minutes.',\n",
              "       'saint-andre anger at absent stars sale sharks director of rugby philippe saint-andre has re-opened rugby s club-versus-country debate.  sale host bath in the powergen cup on friday  but the frenchman has endured a  difficult week  with six players away on england s six nations training camp.  it s an important game but we ve just the one full session. it s the same for everyone but we need to manage it.  if five players or more are picked for your country they should move the date of the game   he told bbc sport. unless the authorities agree to make changes  saint-andre believes england s national team will suffer as clubs opt to sign foreigners and retired internationals.  that s not good for the politics of the english team or for english rugby   he argues. it is an issue he has taken up before  most notably during the autumn internationals when sale lost all three zurich premiership matches they played.  now he fears it could derail the club s hopes of cup silverware after eight players  including captain jason robinson and fly-half charlie hodgson  were away with their countries.  we re in the quarter-finals  it s always better to play at home than away and it s a great opportunity   he added.  but we have to be careful. bath have just been knocked out of europe and will make it a tough game. it also comes at the end of a very  very difficult week.  sebastien bruno s been with france  jason white with scotland and there are six with england  that s eight players plus injuries - 13 players out of a squad of 31.  we ll have just one session together and will have to do our best to make that a good one on thursday afternoon.   gloucester have also been caught in a club-versus-country conflict after england sought a second medical opinion on james simpson-daniel s fitness. the winger is carrying a shoulder injury and the national team management believe he requires time on the sidelines. as a result he misses the cherry and white s quarter-final at home to bristol.  under the elite player squad agreement  england wanted a second opinion  which they can do   director of rugby nigel melville told the gloucester citizen.   they obviously want him for international rugby and we want him for club rugby in what is a very important game for us. there is a conflict of interests.  the surgeon who carried out his operation said he was fine for us but england say he is still vulnerable to be damaged again and want him on a full rehab programme.  simpson-daniel added:  i ve said to nigel i want to be back playing and that means if everything goes well this week  i can target the worcester game (on 29 january) for a return.',\n",
              "       'watchdog probes e-mail deletions the information commissioner says he is urgen'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4vklLAj1lIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "\n",
        "i=0\n",
        "\n",
        "for value in tulisan_text:\n",
        "  text = value\n",
        "  for word in STOPWORDS:\n",
        "    token = \" \" + word + \" \"\n",
        "    text = text.replace(token, \" \")\n",
        "    text = text.replace(\"  \", \" \")\n",
        "  tulisan_text[i] = text\n",
        "  i=i+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlNfJmmS9VJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "text_latih, text_test, label_latih, label_test = train_test_split(tulisan_text, category, test_size=0.2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH7ULTx4tHLz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "12d5cf34-2d13-4fe4-e2ef-25130eac8a65"
      },
      "source": [
        "print(len(text_latih))\n",
        "print(len(text_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1470\n",
            "368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhCbpKUN9prO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        " \n",
        "tokenizer = Tokenizer(num_words=5000, oov_token='x')\n",
        "tokenizer.fit_on_texts(text_latih) \n",
        "tokenizer.fit_on_texts(text_test)\n",
        " \n",
        "sekuens_latih = tokenizer.texts_to_sequences(text_latih)\n",
        "sekuens_test = tokenizer.texts_to_sequences(text_test)\n",
        " \n",
        "padded_latih = pad_sequences(sekuens_latih, maxlen=200, padding='post', truncating='post')\n",
        "padded_test = pad_sequences(sekuens_test, maxlen=200, padding='post', truncating='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IVxzKpWS8LJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "5514456e-b129-41ed-833d-a297ad209666"
      },
      "source": [
        "padded_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2418,   56, 1925, ...,   52, 1931, 2039],\n",
              "       [2418, 1602, 1173, ...,    0,    0,    0],\n",
              "       [ 669,  552, 4489, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [ 184, 2418, 1279, ..., 1036, 2418,   33],\n",
              "       [3881, 1121,   11, ...,    0,    0,    0],\n",
              "       [ 111,  160, 1263, ...,  469, 2384,  120]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNSlVkMn910E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=5000, output_dim=64),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "#tf.keras.layers.Dense(128, activation='relu'),"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCCeLpRhbKBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "\n",
        "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "  def on_epoch_begin(self, epoch, logs=None):\n",
        "      keys = list(logs.keys())\n",
        "      print(\"Dimulai epoch ke-{}; pada waktu {}\".format(epoch, datetime.datetime.now().time()))\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "      keys = list(logs.keys())\n",
        "      print(\"Berakhir epoch ke-{}; pada waktu {}\".format(epoch, datetime.datetime.now().time()))\n",
        "\n",
        "  def on_train_batch_begin(self, batch, logs=None):\n",
        "    print('\\nTraining batch ke-{} dimulai pada {}'.format(batch, datetime.datetime.now().time()))\n",
        "\n",
        "  def on_train_batch_end(self, batch, logs=None):\n",
        "    print('Training batch ke-{} berakhir pada {}'.format(batch, datetime.datetime.now().time()))\n",
        "\n",
        "  def on_test_batch_begin(self, batch, logs=None):\n",
        "    print('\\nEvaluating batch ke-{} dimulai pada {}'.format(batch, datetime.datetime.now().time()))\n",
        "\n",
        "  def on_test_batch_end(self, batch, logs=None):\n",
        "    print('\\nEvaluating batch ke-{} berakhir pada {}'.format(batch, datetime.datetime.now().time()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1VpDelmBfiy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d1d442c7-4a05-4ed0-e223-185753fa208c"
      },
      "source": [
        "num_epochs = 10\n",
        "history = model.fit(padded_latih,\n",
        "                    label_latih,\n",
        "                    epochs=num_epochs,\n",
        "                    callbacks=[MyCustomCallback()],\n",
        "                    validation_data=(padded_test, label_test),\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimulai epoch ke-0; pada waktu 12:08:37.482862\n",
            "Epoch 1/10\n",
            "\n",
            "Training batch ke-0 dimulai pada 12:08:37.483615\n",
            "Training batch ke-0 berakhir pada 12:08:41.032119\n",
            " 1/46 [..............................] - ETA: 0s - loss: 1.6094 - accuracy: 0.2812\n",
            "Training batch ke-1 dimulai pada 12:08:41.033624\n",
            "Training batch ke-1 berakhir pada 12:08:41.232112\n",
            " 2/46 [>.............................] - ETA: 4s - loss: 1.6067 - accuracy: 0.3438\n",
            "Training batch ke-2 dimulai pada 12:08:41.233400\n",
            "Training batch ke-2 berakhir pada 12:08:41.443994\n",
            " 3/46 [>.............................] - ETA: 5s - loss: 1.6066 - accuracy: 0.3021\n",
            "Training batch ke-3 dimulai pada 12:08:41.445621\n",
            "Training batch ke-3 berakhir pada 12:08:41.664680\n",
            " 4/46 [=>............................] - ETA: 6s - loss: 1.6061 - accuracy: 0.2969\n",
            "Training batch ke-4 dimulai pada 12:08:41.666247\n",
            "Training batch ke-4 berakhir pada 12:08:41.872825\n",
            " 5/46 [==>...........................] - ETA: 6s - loss: 1.6051 - accuracy: 0.2812\n",
            "Training batch ke-5 dimulai pada 12:08:41.874567\n",
            "Training batch ke-5 berakhir pada 12:08:42.091247\n",
            " 6/46 [==>...........................] - ETA: 7s - loss: 1.6054 - accuracy: 0.2708\n",
            "Training batch ke-6 dimulai pada 12:08:42.092721\n",
            "Training batch ke-6 berakhir pada 12:08:42.294415\n",
            " 7/46 [===>..........................] - ETA: 7s - loss: 1.6039 - accuracy: 0.2902\n",
            "Training batch ke-7 dimulai pada 12:08:42.296797\n",
            "Training batch ke-7 berakhir pada 12:08:42.507414\n",
            " 8/46 [====>.........................] - ETA: 7s - loss: 1.6044 - accuracy: 0.2930\n",
            "Training batch ke-8 dimulai pada 12:08:42.508670\n",
            "Training batch ke-8 berakhir pada 12:08:42.724424\n",
            " 9/46 [====>.........................] - ETA: 6s - loss: 1.6026 - accuracy: 0.3021\n",
            "Training batch ke-9 dimulai pada 12:08:42.726049\n",
            "Training batch ke-9 berakhir pada 12:08:42.924284\n",
            "10/46 [=====>........................] - ETA: 6s - loss: 1.6028 - accuracy: 0.2969\n",
            "Training batch ke-10 dimulai pada 12:08:42.925532\n",
            "Training batch ke-10 berakhir pada 12:08:43.133293\n",
            "11/46 [======>.......................] - ETA: 6s - loss: 1.6021 - accuracy: 0.2869\n",
            "Training batch ke-11 dimulai pada 12:08:43.134576\n",
            "Training batch ke-11 berakhir pada 12:08:43.341243\n",
            "12/46 [======>.......................] - ETA: 6s - loss: 1.6005 - accuracy: 0.2969\n",
            "Training batch ke-12 dimulai pada 12:08:43.342840\n",
            "Training batch ke-12 berakhir pada 12:08:43.543367\n",
            "13/46 [=======>......................] - ETA: 6s - loss: 1.6001 - accuracy: 0.3005\n",
            "Training batch ke-13 dimulai pada 12:08:43.549525\n",
            "Training batch ke-13 berakhir pada 12:08:43.759662\n",
            "14/46 [========>.....................] - ETA: 6s - loss: 1.5980 - accuracy: 0.3036\n",
            "Training batch ke-14 dimulai pada 12:08:43.761026\n",
            "Training batch ke-14 berakhir pada 12:08:43.954246\n",
            "15/46 [========>.....................] - ETA: 6s - loss: 1.5973 - accuracy: 0.2979\n",
            "Training batch ke-15 dimulai pada 12:08:43.955829\n",
            "Training batch ke-15 berakhir pada 12:08:44.157184\n",
            "16/46 [=========>....................] - ETA: 5s - loss: 1.5956 - accuracy: 0.3008\n",
            "Training batch ke-16 dimulai pada 12:08:44.158753\n",
            "Training batch ke-16 berakhir pada 12:08:44.351205\n",
            "17/46 [==========>...................] - ETA: 5s - loss: 1.5931 - accuracy: 0.3033\n",
            "Training batch ke-17 dimulai pada 12:08:44.352466\n",
            "Training batch ke-17 berakhir pada 12:08:44.558629\n",
            "18/46 [==========>...................] - ETA: 5s - loss: 1.5932 - accuracy: 0.2986\n",
            "Training batch ke-18 dimulai pada 12:08:44.559943\n",
            "Training batch ke-18 berakhir pada 12:08:44.762722\n",
            "19/46 [===========>..................] - ETA: 5s - loss: 1.5931 - accuracy: 0.2944\n",
            "Training batch ke-19 dimulai pada 12:08:44.765731\n",
            "Training batch ke-19 berakhir pada 12:08:44.959314\n",
            "20/46 [============>.................] - ETA: 5s - loss: 1.5928 - accuracy: 0.2906\n",
            "Training batch ke-20 dimulai pada 12:08:44.960928\n",
            "Training batch ke-20 berakhir pada 12:08:45.158207\n",
            "21/46 [============>.................] - ETA: 4s - loss: 1.5875 - accuracy: 0.3006\n",
            "Training batch ke-21 dimulai pada 12:08:45.159470\n",
            "Training batch ke-21 berakhir pada 12:08:45.356784\n",
            "22/46 [=============>................] - ETA: 4s - loss: 1.5836 - accuracy: 0.2997\n",
            "Training batch ke-22 dimulai pada 12:08:45.358125\n",
            "Training batch ke-22 berakhir pada 12:08:45.554803\n",
            "23/46 [==============>...............] - ETA: 4s - loss: 1.5827 - accuracy: 0.2962\n",
            "Training batch ke-23 dimulai pada 12:08:45.556080\n",
            "Training batch ke-23 berakhir pada 12:08:45.759343\n",
            "24/46 [==============>...............] - ETA: 4s - loss: 1.5823 - accuracy: 0.2904\n",
            "Training batch ke-24 dimulai pada 12:08:45.760959\n",
            "Training batch ke-24 berakhir pada 12:08:45.953216\n",
            "25/46 [===============>..............] - ETA: 4s - loss: 1.5823 - accuracy: 0.2925\n",
            "Training batch ke-25 dimulai pada 12:08:45.954432\n",
            "Training batch ke-25 berakhir pada 12:08:46.150455\n",
            "26/46 [===============>..............] - ETA: 3s - loss: 1.5816 - accuracy: 0.2921\n",
            "Training batch ke-26 dimulai pada 12:08:46.151719\n",
            "Training batch ke-26 berakhir pada 12:08:46.345182\n",
            "27/46 [================>.............] - ETA: 3s - loss: 1.5796 - accuracy: 0.2917\n",
            "Training batch ke-27 dimulai pada 12:08:46.346449\n",
            "Training batch ke-27 berakhir pada 12:08:46.555292\n",
            "28/46 [=================>............] - ETA: 3s - loss: 1.5823 - accuracy: 0.2857\n",
            "Training batch ke-28 dimulai pada 12:08:46.556692\n",
            "Training batch ke-28 berakhir pada 12:08:46.761947\n",
            "29/46 [=================>............] - ETA: 3s - loss: 1.5793 - accuracy: 0.2856\n",
            "Training batch ke-29 dimulai pada 12:08:46.763188\n",
            "Training batch ke-29 berakhir pada 12:08:46.955080\n",
            "30/46 [==================>...........] - ETA: 3s - loss: 1.5743 - accuracy: 0.2854\n",
            "Training batch ke-30 dimulai pada 12:08:46.956310\n",
            "Training batch ke-30 berakhir pada 12:08:47.165675\n",
            "31/46 [===================>..........] - ETA: 2s - loss: 1.5723 - accuracy: 0.2893\n",
            "Training batch ke-31 dimulai pada 12:08:47.166873\n",
            "Training batch ke-31 berakhir pada 12:08:47.358028\n",
            "32/46 [===================>..........] - ETA: 2s - loss: 1.5631 - accuracy: 0.2969\n",
            "Training batch ke-32 dimulai pada 12:08:47.359332\n",
            "Training batch ke-32 berakhir pada 12:08:47.568766\n",
            "33/46 [====================>.........] - ETA: 2s - loss: 1.5697 - accuracy: 0.2917\n",
            "Training batch ke-33 dimulai pada 12:08:47.570494\n",
            "Training batch ke-33 berakhir pada 12:08:47.771192\n",
            "34/46 [=====================>........] - ETA: 2s - loss: 1.5645 - accuracy: 0.2932\n",
            "Training batch ke-34 dimulai pada 12:08:47.773123\n",
            "Training batch ke-34 berakhir pada 12:08:47.964408\n",
            "35/46 [=====================>........] - ETA: 2s - loss: 1.5598 - accuracy: 0.2937\n",
            "Training batch ke-35 dimulai pada 12:08:47.965884\n",
            "Training batch ke-35 berakhir pada 12:08:48.173312\n",
            "36/46 [======================>.......] - ETA: 1s - loss: 1.5596 - accuracy: 0.2934\n",
            "Training batch ke-36 dimulai pada 12:08:48.175039\n",
            "Training batch ke-36 berakhir pada 12:08:48.376036\n",
            "37/46 [=======================>......] - ETA: 1s - loss: 1.5556 - accuracy: 0.2965\n",
            "Training batch ke-37 dimulai pada 12:08:48.378779\n",
            "Training batch ke-37 berakhir pada 12:08:48.572189\n",
            "38/46 [=======================>......] - ETA: 1s - loss: 1.5515 - accuracy: 0.2985\n",
            "Training batch ke-38 dimulai pada 12:08:48.573619\n",
            "Training batch ke-38 berakhir pada 12:08:48.774517\n",
            "39/46 [========================>.....] - ETA: 1s - loss: 1.5487 - accuracy: 0.2997\n",
            "Training batch ke-39 dimulai pada 12:08:48.775843\n",
            "Training batch ke-39 berakhir pada 12:08:48.971428\n",
            "40/46 [=========================>....] - ETA: 1s - loss: 1.5455 - accuracy: 0.3023\n",
            "Training batch ke-40 dimulai pada 12:08:48.972635\n",
            "Training batch ke-40 berakhir pada 12:08:49.168755\n",
            "41/46 [=========================>....] - ETA: 0s - loss: 1.5449 - accuracy: 0.3011\n",
            "Training batch ke-41 dimulai pada 12:08:49.170361\n",
            "Training batch ke-41 berakhir pada 12:08:49.362795\n",
            "42/46 [==========================>...] - ETA: 0s - loss: 1.5409 - accuracy: 0.3065\n",
            "Training batch ke-42 dimulai pada 12:08:49.364086\n",
            "Training batch ke-42 berakhir pada 12:08:49.558558\n",
            "43/46 [===========================>..] - ETA: 0s - loss: 1.5358 - accuracy: 0.3132\n",
            "Training batch ke-43 dimulai pada 12:08:49.559788\n",
            "Training batch ke-43 berakhir pada 12:08:49.750492\n",
            "44/46 [===========================>..] - ETA: 0s - loss: 1.5299 - accuracy: 0.3182\n",
            "Training batch ke-44 dimulai pada 12:08:49.751748\n",
            "Training batch ke-44 berakhir pada 12:08:49.950200\n",
            "45/46 [============================>.] - ETA: 0s - loss: 1.5248 - accuracy: 0.3222\n",
            "Training batch ke-45 dimulai pada 12:08:49.951417\n",
            "Training batch ke-45 berakhir pada 12:08:50.136412\n",
            "46/46 [==============================] - ETA: 0s - loss: 1.5200 - accuracy: 0.3265\n",
            "Evaluating batch ke-0 dimulai pada 12:08:50.183497\n",
            "\n",
            "Evaluating batch ke-0 berakhir pada 12:08:50.972882\n",
            "\n",
            "Evaluating batch ke-1 dimulai pada 12:08:50.973163\n",
            "\n",
            "Evaluating batch ke-1 berakhir pada 12:08:51.012629\n",
            "\n",
            "Evaluating batch ke-2 dimulai pada 12:08:51.012848\n",
            "\n",
            "Evaluating batch ke-2 berakhir pada 12:08:51.051121\n",
            "\n",
            "Evaluating batch ke-3 dimulai pada 12:08:51.051322\n",
            "\n",
            "Evaluating batch ke-3 berakhir pada 12:08:51.091739\n",
            "\n",
            "Evaluating batch ke-4 dimulai pada 12:08:51.091965\n",
            "\n",
            "Evaluating batch ke-4 berakhir pada 12:08:51.131468\n",
            "\n",
            "Evaluating batch ke-5 dimulai pada 12:08:51.131666\n",
            "\n",
            "Evaluating batch ke-5 berakhir pada 12:08:51.170482\n",
            "\n",
            "Evaluating batch ke-6 dimulai pada 12:08:51.170673\n",
            "\n",
            "Evaluating batch ke-6 berakhir pada 12:08:51.215589\n",
            "\n",
            "Evaluating batch ke-7 dimulai pada 12:08:51.215870\n",
            "\n",
            "Evaluating batch ke-7 berakhir pada 12:08:51.254791\n",
            "\n",
            "Evaluating batch ke-8 dimulai pada 12:08:51.255013\n",
            "\n",
            "Evaluating batch ke-8 berakhir pada 12:08:51.294396\n",
            "\n",
            "Evaluating batch ke-9 dimulai pada 12:08:51.294594\n",
            "\n",
            "Evaluating batch ke-9 berakhir pada 12:08:51.335269\n",
            "\n",
            "Evaluating batch ke-10 dimulai pada 12:08:51.335471\n",
            "\n",
            "Evaluating batch ke-10 berakhir pada 12:08:51.373114\n",
            "\n",
            "Evaluating batch ke-11 dimulai pada 12:08:51.373304\n",
            "\n",
            "Evaluating batch ke-11 berakhir pada 12:08:51.398062\n",
            "Berakhir epoch ke-0; pada waktu 12:08:51.400015\n",
            "46/46 [==============================] - 10s 225ms/step - loss: 1.5200 - accuracy: 0.3265 - val_loss: 1.4428 - val_accuracy: 0.4076\n",
            "Dimulai epoch ke-1; pada waktu 12:08:51.402300\n",
            "Epoch 2/10\n",
            "\n",
            "Training batch ke-0 dimulai pada 12:08:51.402470\n",
            "Training batch ke-0 berakhir pada 12:08:51.600408\n",
            " 1/46 [..............................] - ETA: 0s - loss: 1.4167 - accuracy: 0.2188\n",
            "Training batch ke-1 dimulai pada 12:08:51.601648\n",
            "Training batch ke-1 berakhir pada 12:08:51.801953\n",
            " 2/46 [>.............................] - ETA: 4s - loss: 1.4211 - accuracy: 0.3281\n",
            "Training batch ke-2 dimulai pada 12:08:51.803424\n",
            "Training batch ke-2 berakhir pada 12:08:52.000067\n",
            " 3/46 [>.............................] - ETA: 5s - loss: 1.4295 - accuracy: 0.3750\n",
            "Training batch ke-3 dimulai pada 12:08:52.001373\n",
            "Training batch ke-3 berakhir pada 12:08:52.194256\n",
            " 4/46 [=>............................] - ETA: 6s - loss: 1.4822 - accuracy: 0.3594\n",
            "Training batch ke-4 dimulai pada 12:08:52.195538\n",
            "Training batch ke-4 berakhir pada 12:08:52.391717\n",
            " 5/46 [==>...........................] - ETA: 6s - loss: 1.4488 - accuracy: 0.3812\n",
            "Training batch ke-5 dimulai pada 12:08:52.392943\n",
            "Training batch ke-5 berakhir pada 12:08:52.585697\n",
            " 6/46 [==>...........................] - ETA: 6s - loss: 1.4648 - accuracy: 0.3802\n",
            "Training batch ke-6 dimulai pada 12:08:52.587004\n",
            "Training batch ke-6 berakhir pada 12:08:52.778191\n",
            " 7/46 [===>..........................] - ETA: 6s - loss: 1.4592 - accuracy: 0.3795\n",
            "Training batch ke-7 dimulai pada 12:08:52.779444\n",
            "Training batch ke-7 berakhir pada 12:08:52.978358\n",
            " 8/46 [====>.........................] - ETA: 6s - loss: 1.4383 - accuracy: 0.3750\n",
            "Training batch ke-8 dimulai pada 12:08:52.980190\n",
            "Training batch ke-8 berakhir pada 12:08:53.176720\n",
            " 9/46 [====>.........................] - ETA: 6s - loss: 1.4355 - accuracy: 0.3785\n",
            "Training batch ke-9 dimulai pada 12:08:53.177964\n",
            "Training batch ke-9 berakhir pada 12:08:53.371395\n",
            "10/46 [=====>........................] - ETA: 6s - loss: 1.4298 - accuracy: 0.3875\n",
            "Training batch ke-10 dimulai pada 12:08:53.372635\n",
            "Training batch ke-10 berakhir pada 12:08:53.562099\n",
            "11/46 [======>.......................] - ETA: 6s - loss: 1.4120 - accuracy: 0.3949\n",
            "Training batch ke-11 dimulai pada 12:08:53.563223\n",
            "Training batch ke-11 berakhir pada 12:08:53.752972\n",
            "12/46 [======>.......................] - ETA: 6s - loss: 1.4168 - accuracy: 0.3984\n",
            "Training batch ke-12 dimulai pada 12:08:53.754201\n",
            "Training batch ke-12 berakhir pada 12:08:53.954086\n",
            "13/46 [=======>......................] - ETA: 5s - loss: 1.4227 - accuracy: 0.3918\n",
            "Training batch ke-13 dimulai pada 12:08:53.955815\n",
            "Training batch ke-13 berakhir pada 12:08:54.145219\n",
            "14/46 [========>.....................] - ETA: 5s - loss: 1.4253 - accuracy: 0.3973\n",
            "Training batch ke-14 dimulai pada 12:08:54.146773\n",
            "Training batch ke-14 berakhir pada 12:08:54.341640\n",
            "15/46 [========>.....................] - ETA: 5s - loss: 1.4145 - accuracy: 0.4083\n",
            "Training batch ke-15 dimulai pada 12:08:54.342840\n",
            "Training batch ke-15 berakhir pada 12:08:54.532439\n",
            "16/46 [=========>....................] - ETA: 5s - loss: 1.4113 - accuracy: 0.4121\n",
            "Training batch ke-16 dimulai pada 12:08:54.533698\n",
            "Training batch ke-16 berakhir pada 12:08:54.729876\n",
            "17/46 [==========>...................] - ETA: 5s - loss: 1.4055 - accuracy: 0.4136\n",
            "Training batch ke-17 dimulai pada 12:08:54.731858\n",
            "Training batch ke-17 berakhir pada 12:08:54.928739\n",
            "18/46 [==========>...................] - ETA: 5s - loss: 1.4023 - accuracy: 0.4219\n",
            "Training batch ke-18 dimulai pada 12:08:54.929945\n",
            "Training batch ke-18 berakhir pada 12:08:55.121841\n",
            "19/46 [===========>..................] - ETA: 5s - loss: 1.3975 - accuracy: 0.4309\n",
            "Training batch ke-19 dimulai pada 12:08:55.123200\n",
            "Training batch ke-19 berakhir pada 12:08:55.310933\n",
            "20/46 [============>.................] - ETA: 4s - loss: 1.3890 - accuracy: 0.4344\n",
            "Training batch ke-20 dimulai pada 12:08:55.312233\n",
            "Training batch ke-20 berakhir pada 12:08:55.508100\n",
            "21/46 [============>.................] - ETA: 4s - loss: 1.3775 - accuracy: 0.4390\n",
            "Training batch ke-21 dimulai pada 12:08:55.509742\n",
            "Training batch ke-21 berakhir pada 12:08:55.701551\n",
            "22/46 [=============>................] - ETA: 4s - loss: 1.3701 - accuracy: 0.4460\n",
            "Training batch ke-22 dimulai pada 12:08:55.702785\n",
            "Training batch ke-22 berakhir pada 12:08:55.892003\n",
            "23/46 [==============>...............] - ETA: 4s - loss: 1.3536 - accuracy: 0.4552\n",
            "Training batch ke-23 dimulai pada 12:08:55.893257\n",
            "Training batch ke-23 berakhir pada 12:08:56.100416\n",
            "24/46 [==============>...............] - ETA: 4s - loss: 1.3499 - accuracy: 0.4557\n",
            "Training batch ke-24 dimulai pada 12:08:56.101658\n",
            "Training batch ke-24 berakhir pada 12:08:56.291334\n",
            "25/46 [===============>..............] - ETA: 3s - loss: 1.3387 - accuracy: 0.4600\n",
            "Training batch ke-25 dimulai pada 12:08:56.292558\n",
            "Training batch ke-25 berakhir pada 12:08:56.487771\n",
            "26/46 [===============>..............] - ETA: 3s - loss: 1.3253 - accuracy: 0.4639\n",
            "Training batch ke-26 dimulai pada 12:08:56.489065\n",
            "Training batch ke-26 berakhir pada 12:08:56.678974\n",
            "27/46 [================>.............] - ETA: 3s - loss: 1.3216 - accuracy: 0.4641\n",
            "Training batch ke-27 dimulai pada 12:08:56.680229\n",
            "Training batch ke-27 berakhir pada 12:08:56.868747\n",
            "28/46 [=================>............] - ETA: 3s - loss: 1.3132 - accuracy: 0.4676\n",
            "Training batch ke-28 dimulai pada 12:08:56.870059\n",
            "Training batch ke-28 berakhir pada 12:08:57.073456\n",
            "29/46 [=================>............] - ETA: 3s - loss: 1.2978 - accuracy: 0.4763\n",
            "Training batch ke-29 dimulai pada 12:08:57.074744\n",
            "Training batch ke-29 berakhir pada 12:08:57.261453\n",
            "30/46 [==================>...........] - ETA: 3s - loss: 1.2955 - accuracy: 0.4740\n",
            "Training batch ke-30 dimulai pada 12:08:57.262646\n",
            "Training batch ke-30 berakhir pada 12:08:57.458623\n",
            "31/46 [===================>..........] - ETA: 2s - loss: 1.2854 - accuracy: 0.4788\n",
            "Training batch ke-31 dimulai pada 12:08:57.459740\n",
            "Training batch ke-31 berakhir pada 12:08:57.653751\n",
            "32/46 [===================>..........] - ETA: 2s - loss: 1.2803 - accuracy: 0.4766\n",
            "Training batch ke-32 dimulai pada 12:08:57.655071\n",
            "Training batch ke-32 berakhir pada 12:08:57.851666\n",
            "33/46 [====================>.........] - ETA: 2s - loss: 1.2673 - accuracy: 0.4830\n",
            "Training batch ke-33 dimulai pada 12:08:57.852805\n",
            "Training batch ke-33 berakhir pada 12:08:58.051270\n",
            "34/46 [=====================>........] - ETA: 2s - loss: 1.2604 - accuracy: 0.4825\n",
            "Training batch ke-34 dimulai pada 12:08:58.052545\n",
            "Training batch ke-34 berakhir pada 12:08:58.246707\n",
            "35/46 [=====================>........] - ETA: 2s - loss: 1.2493 - accuracy: 0.4875\n",
            "Training batch ke-35 dimulai pada 12:08:58.248015\n",
            "Training batch ke-35 berakhir pada 12:08:58.441712\n",
            "36/46 [======================>.......] - ETA: 1s - loss: 1.2416 - accuracy: 0.4887\n",
            "Training batch ke-36 dimulai pada 12:08:58.443265\n",
            "Training batch ke-36 berakhir pada 12:08:58.634451\n",
            "37/46 [=======================>......] - ETA: 1s - loss: 1.2411 - accuracy: 0.4916\n",
            "Training batch ke-37 dimulai pada 12:08:58.635686\n",
            "Training batch ke-37 berakhir pada 12:08:58.827533\n",
            "38/46 [=======================>......] - ETA: 1s - loss: 1.2361 - accuracy: 0.4934\n",
            "Training batch ke-38 dimulai pada 12:08:58.828772\n",
            "Training batch ke-38 berakhir pada 12:08:59.028920\n",
            "39/46 [========================>.....] - ETA: 1s - loss: 1.2271 - accuracy: 0.4960\n",
            "Training batch ke-39 dimulai pada 12:08:59.030464\n",
            "Training batch ke-39 berakhir pada 12:08:59.223534\n",
            "40/46 [=========================>....] - ETA: 1s - loss: 1.2196 - accuracy: 0.5000\n",
            "Training batch ke-40 dimulai pada 12:08:59.224750\n",
            "Training batch ke-40 berakhir pada 12:08:59.418206\n",
            "41/46 [=========================>....] - ETA: 0s - loss: 1.2153 - accuracy: 0.5015\n",
            "Training batch ke-41 dimulai pada 12:08:59.419438\n",
            "Training batch ke-41 berakhir pada 12:08:59.611488\n",
            "42/46 [==========================>...] - ETA: 0s - loss: 1.2086 - accuracy: 0.5030\n",
            "Training batch ke-42 dimulai pada 12:08:59.612777\n",
            "Training batch ke-42 berakhir pada 12:08:59.806407\n",
            "43/46 [===========================>..] - ETA: 0s - loss: 1.2002 - accuracy: 0.5065\n",
            "Training batch ke-43 dimulai pada 12:08:59.807650\n",
            "Training batch ke-43 berakhir pada 12:09:00.005445\n",
            "44/46 [===========================>..] - ETA: 0s - loss: 1.1905 - accuracy: 0.5107\n",
            "Training batch ke-44 dimulai pada 12:09:00.006750\n",
            "Training batch ke-44 berakhir pada 12:09:00.197789\n",
            "45/46 [============================>.] - ETA: 0s - loss: 1.1827 - accuracy: 0.5132\n",
            "Training batch ke-45 dimulai pada 12:09:00.199422\n",
            "Training batch ke-45 berakhir pada 12:09:00.380381\n",
            "46/46 [==============================] - ETA: 0s - loss: 1.1749 - accuracy: 0.5150\n",
            "Evaluating batch ke-0 dimulai pada 12:09:00.399241\n",
            "\n",
            "Evaluating batch ke-0 berakhir pada 12:09:00.441313\n",
            "\n",
            "Evaluating batch ke-1 dimulai pada 12:09:00.441525\n",
            "\n",
            "Evaluating batch ke-1 berakhir pada 12:09:00.478222\n",
            "\n",
            "Evaluating batch ke-2 dimulai pada 12:09:00.478419\n",
            "\n",
            "Evaluating batch ke-2 berakhir pada 12:09:00.516573\n",
            "\n",
            "Evaluating batch ke-3 dimulai pada 12:09:00.516766\n",
            "\n",
            "Evaluating batch ke-3 berakhir pada 12:09:00.555166\n",
            "\n",
            "Evaluating batch ke-4 dimulai pada 12:09:00.555359\n",
            "\n",
            "Evaluating batch ke-4 berakhir pada 12:09:00.598357\n",
            "\n",
            "Evaluating batch ke-5 dimulai pada 12:09:00.598560\n",
            "\n",
            "Evaluating batch ke-5 berakhir pada 12:09:00.642002\n",
            "\n",
            "Evaluating batch ke-6 dimulai pada 12:09:00.642281\n",
            "\n",
            "Evaluating batch ke-6 berakhir pada 12:09:00.690167\n",
            "\n",
            "Evaluating batch ke-7 dimulai pada 12:09:00.690370\n",
            "\n",
            "Evaluating batch ke-7 berakhir pada 12:09:00.727765\n",
            "\n",
            "Evaluating batch ke-8 dimulai pada 12:09:00.727986\n",
            "\n",
            "Evaluating batch ke-8 berakhir pada 12:09:00.765698\n",
            "\n",
            "Evaluating batch ke-9 dimulai pada 12:09:00.765911\n",
            "\n",
            "Evaluating batch ke-9 berakhir pada 12:09:00.807594\n",
            "\n",
            "Evaluating batch ke-10 dimulai pada 12:09:00.807802\n",
            "\n",
            "Evaluating batch ke-10 berakhir pada 12:09:00.846940\n",
            "\n",
            "Evaluating batch ke-11 dimulai pada 12:09:00.847143\n",
            "\n",
            "Evaluating batch ke-11 berakhir pada 12:09:00.873015\n",
            "Berakhir epoch ke-1; pada waktu 12:09:00.874553\n",
            "46/46 [==============================] - 9s 202ms/step - loss: 1.1749 - accuracy: 0.5150 - val_loss: 0.9234 - val_accuracy: 0.6033\n",
            "Dimulai epoch ke-2; pada waktu 12:09:00.876885\n",
            "Epoch 3/10\n",
            "\n",
            "Training batch ke-0 dimulai pada 12:09:00.877117\n",
            "Training batch ke-0 berakhir pada 12:09:01.079242\n",
            " 1/46 [..............................] - ETA: 0s - loss: 0.8757 - accuracy: 0.6250\n",
            "Training batch ke-1 dimulai pada 12:09:01.080497\n",
            "Training batch ke-1 berakhir pada 12:09:01.269273\n",
            " 2/46 [>.............................] - ETA: 4s - loss: 0.8622 - accuracy: 0.5781\n",
            "Training batch ke-2 dimulai pada 12:09:01.270495\n",
            "Training batch ke-2 berakhir pada 12:09:01.460606\n",
            " 3/46 [>.............................] - ETA: 5s - loss: 0.8693 - accuracy: 0.5833\n",
            "Training batch ke-3 dimulai pada 12:09:01.461856\n",
            "Training batch ke-3 berakhir pada 12:09:01.655186\n",
            " 4/46 [=>............................] - ETA: 6s - loss: 0.8575 - accuracy: 0.5781\n",
            "Training batch ke-4 dimulai pada 12:09:01.656400\n",
            "Training batch ke-4 berakhir pada 12:09:01.848355\n",
            " 5/46 [==>...........................] - ETA: 6s - loss: 0.8652 - accuracy: 0.5750\n",
            "Training batch ke-5 dimulai pada 12:09:01.849561\n",
            "Training batch ke-5 berakhir pada 12:09:02.052109\n",
            " 6/46 [==>...........................] - ETA: 6s - loss: 0.8446 - accuracy: 0.5833\n",
            "Training batch ke-6 dimulai pada 12:09:02.053359\n",
            "Training batch ke-6 berakhir pada 12:09:02.241834\n",
            " 7/46 [===>..........................] - ETA: 6s - loss: 0.8207 - accuracy: 0.6027\n",
            "Training batch ke-7 dimulai pada 12:09:02.243100\n",
            "Training batch ke-7 berakhir pada 12:09:02.433300\n",
            " 8/46 [====>.........................] - ETA: 6s - loss: 0.8092 - accuracy: 0.5977\n",
            "Training batch ke-8 dimulai pada 12:09:02.434664\n",
            "Training batch ke-8 berakhir pada 12:09:02.627569\n",
            " 9/46 [====>.........................] - ETA: 6s - loss: 0.8046 - accuracy: 0.5903\n",
            "Training batch ke-9 dimulai pada 12:09:02.628827\n",
            "Training batch ke-9 berakhir pada 12:09:02.822757\n",
            "10/46 [=====>........................] - ETA: 6s - loss: 0.8055 - accuracy: 0.5813\n",
            "Training batch ke-10 dimulai pada 12:09:02.824002\n",
            "Training batch ke-10 berakhir pada 12:09:03.017175\n",
            "11/46 [======>.......................] - ETA: 6s - loss: 0.8075 - accuracy: 0.5795\n",
            "Training batch ke-11 dimulai pada 12:09:03.018604\n",
            "Training batch ke-11 berakhir pada 12:09:03.229055\n",
            "12/46 [======>.......................] - ETA: 6s - loss: 0.7965 - accuracy: 0.5859\n",
            "Training batch ke-12 dimulai pada 12:09:03.230589\n",
            "Training batch ke-12 berakhir pada 12:09:03.445006\n",
            "13/46 [=======>......................] - ETA: 6s - loss: 0.7895 - accuracy: 0.5986\n",
            "Training batch ke-13 dimulai pada 12:09:03.446296\n",
            "Training batch ke-13 berakhir pada 12:09:03.633453\n",
            "14/46 [========>.....................] - ETA: 5s - loss: 0.7932 - accuracy: 0.6027\n",
            "Training batch ke-14 dimulai pada 12:09:03.635201\n",
            "Training batch ke-14 berakhir pada 12:09:03.823067\n",
            "15/46 [========>.....................] - ETA: 5s - loss: 0.7851 - accuracy: 0.6187\n",
            "Training batch ke-15 dimulai pada 12:09:03.824278\n",
            "Training batch ke-15 berakhir pada 12:09:04.015237\n",
            "16/46 [=========>....................] - ETA: 5s - loss: 0.7832 - accuracy: 0.6250\n",
            "Training batch ke-16 dimulai pada 12:09:04.016488\n",
            "Training batch ke-16 berakhir pada 12:09:04.217543\n",
            "17/46 [==========>...................] - ETA: 5s - loss: 0.7753 - accuracy: 0.6342\n",
            "Training batch ke-17 dimulai pada 12:09:04.220049\n",
            "Training batch ke-17 berakhir pada 12:09:04.411549\n",
            "18/46 [==========>...................] - ETA: 5s - loss: 0.7680 - accuracy: 0.6424\n",
            "Training batch ke-18 dimulai pada 12:09:04.412782\n",
            "Training batch ke-18 berakhir pada 12:09:04.606322\n",
            "19/46 [===========>..................] - ETA: 5s - loss: 0.7504 - accuracy: 0.6546\n",
            "Training batch ke-19 dimulai pada 12:09:04.607585\n",
            "Training batch ke-19 berakhir pada 12:09:04.799662\n",
            "20/46 [============>.................] - ETA: 4s - loss: 0.7398 - accuracy: 0.6625\n",
            "Training batch ke-20 dimulai pada 12:09:04.800850\n",
            "Training batch ke-20 berakhir pada 12:09:05.011731\n",
            "21/46 [============>.................] - ETA: 4s - loss: 0.7322 - accuracy: 0.6667\n",
            "Training batch ke-21 dimulai pada 12:09:05.013041\n",
            "Training batch ke-21 berakhir pada 12:09:05.209763\n",
            "22/46 [=============>................] - ETA: 4s - loss: 0.7194 - accuracy: 0.6733\n",
            "Training batch ke-22 dimulai pada 12:09:05.211081\n",
            "Training batch ke-22 berakhir pada 12:09:05.399260\n",
            "23/46 [==============>...............] - ETA: 4s - loss: 0.7224 - accuracy: 0.6698\n",
            "Training batch ke-23 dimulai pada 12:09:05.400514\n",
            "Training batch ke-23 berakhir pada 12:09:05.593517\n",
            "24/46 [==============>...............] - ETA: 4s - loss: 0.7167 - accuracy: 0.6719\n",
            "Training batch ke-24 dimulai pada 12:09:05.594795\n",
            "Training batch ke-24 berakhir pada 12:09:05.782789\n",
            "25/46 [===============>..............] - ETA: 3s - loss: 0.7094 - accuracy: 0.6775\n",
            "Training batch ke-25 dimulai pada 12:09:05.784037\n",
            "Training batch ke-25 berakhir pada 12:09:05.973027\n",
            "26/46 [===============>..............] - ETA: 3s - loss: 0.7002 - accuracy: 0.6827\n",
            "Training batch ke-26 dimulai pada 12:09:05.974292\n",
            "Training batch ke-26 berakhir pada 12:09:06.174610\n",
            "27/46 [================>.............] - ETA: 3s - loss: 0.6950 - accuracy: 0.6817\n",
            "Training batch ke-27 dimulai pada 12:09:06.175770\n",
            "Training batch ke-27 berakhir pada 12:09:06.363243\n",
            "28/46 [=================>............] - ETA: 3s - loss: 0.6938 - accuracy: 0.6853\n",
            "Training batch ke-28 dimulai pada 12:09:06.364705\n",
            "Training batch ke-28 berakhir pada 12:09:06.554621\n",
            "29/46 [=================>............] - ETA: 3s - loss: 0.7024 - accuracy: 0.6810\n",
            "Training batch ke-29 dimulai pada 12:09:06.556217\n",
            "Training batch ke-29 berakhir pada 12:09:06.744931\n",
            "30/46 [==================>...........] - ETA: 3s - loss: 0.6988 - accuracy: 0.6823\n",
            "Training batch ke-30 dimulai pada 12:09:06.746141\n",
            "Training batch ke-30 berakhir pada 12:09:06.937434\n",
            "31/46 [===================>..........] - ETA: 2s - loss: 0.6886 - accuracy: 0.6865\n",
            "Training batch ke-31 dimulai pada 12:09:06.938711\n",
            "Training batch ke-31 berakhir pada 12:09:07.139136\n",
            "32/46 [===================>..........] - ETA: 2s - loss: 0.6856 - accuracy: 0.6895\n",
            "Training batch ke-32 dimulai pada 12:09:07.140604\n",
            "Training batch ke-32 berakhir pada 12:09:07.330835\n",
            "33/46 [====================>.........] - ETA: 2s - loss: 0.6800 - accuracy: 0.6913\n",
            "Training batch ke-33 dimulai pada 12:09:07.332012\n",
            "Training batch ke-33 berakhir pada 12:09:07.525787\n",
            "34/46 [=====================>........] - ETA: 2s - loss: 0.6738 - accuracy: 0.6939\n",
            "Training batch ke-34 dimulai pada 12:09:07.527453\n",
            "Training batch ke-34 berakhir pada 12:09:07.721568\n",
            "35/46 [=====================>........] - ETA: 2s - loss: 0.6659 - accuracy: 0.6964\n",
            "Training batch ke-35 dimulai pada 12:09:07.722957\n",
            "Training batch ke-35 berakhir pada 12:09:07.920031\n",
            "36/46 [======================>.......] - ETA: 1s - loss: 0.6609 - accuracy: 0.6997\n",
            "Training batch ke-36 dimulai pada 12:09:07.921304\n",
            "Training batch ke-36 berakhir pada 12:09:08.133091\n",
            "37/46 [=======================>......] - ETA: 1s - loss: 0.6571 - accuracy: 0.7010\n",
            "Training batch ke-37 dimulai pada 12:09:08.134527\n",
            "Training batch ke-37 berakhir pada 12:09:08.357210\n",
            "38/46 [=======================>......] - ETA: 1s - loss: 0.6511 - accuracy: 0.7031\n",
            "Training batch ke-38 dimulai pada 12:09:08.358528\n",
            "Training batch ke-38 berakhir pada 12:09:08.568250\n",
            "39/46 [========================>.....] - ETA: 1s - loss: 0.6592 - accuracy: 0.7011\n",
            "Training batch ke-39 dimulai pada 12:09:08.569565\n",
            "Training batch ke-39 berakhir pada 12:09:08.777088\n",
            "40/46 [=========================>....] - ETA: 1s - loss: 0.6544 - accuracy: 0.7039\n",
            "Training batch ke-40 dimulai pada 12:09:08.778434\n",
            "Training batch ke-40 berakhir pada 12:09:08.975505\n",
            "41/46 [=========================>....] - ETA: 0s - loss: 0.6471 - accuracy: 0.7058\n",
            "Training batch ke-41 dimulai pada 12:09:08.977992\n",
            "Training batch ke-41 berakhir pada 12:09:09.198356\n",
            "42/46 [==========================>...] - ETA: 0s - loss: 0.6426 - accuracy: 0.7076\n",
            "Training batch ke-42 dimulai pada 12:09:09.200149\n",
            "Training batch ke-42 berakhir pada 12:09:09.412442\n",
            "43/46 [===========================>..] - ETA: 0s - loss: 0.6398 - accuracy: 0.7071\n",
            "Training batch ke-43 dimulai pada 12:09:09.414086\n",
            "Training batch ke-43 berakhir pada 12:09:09.632924\n",
            "44/46 [===========================>..] - ETA: 0s - loss: 0.6402 - accuracy: 0.7081\n",
            "Training batch ke-44 dimulai pada 12:09:09.634922\n",
            "Training batch ke-44 berakhir pada 12:09:09.850346\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.6366 - accuracy: 0.7104\n",
            "Training batch ke-45 dimulai pada 12:09:09.852429\n",
            "Training batch ke-45 berakhir pada 12:09:10.056643\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.6300 - accuracy: 0.7143\n",
            "Evaluating batch ke-0 dimulai pada 12:09:10.081456\n",
            "\n",
            "Evaluating batch ke-0 berakhir pada 12:09:10.128341\n",
            "\n",
            "Evaluating batch ke-1 dimulai pada 12:09:10.128652\n",
            "\n",
            "Evaluating batch ke-1 berakhir pada 12:09:10.177615\n",
            "\n",
            "Evaluating batch ke-2 dimulai pada 12:09:10.177887\n",
            "\n",
            "Evaluating batch ke-2 berakhir pada 12:09:10.230088\n",
            "\n",
            "Evaluating batch ke-3 dimulai pada 12:09:10.230327\n",
            "\n",
            "Evaluating batch ke-3 berakhir pada 12:09:10.279161\n",
            "\n",
            "Evaluating batch ke-4 dimulai pada 12:09:10.279397\n",
            "\n",
            "Evaluating batch ke-4 berakhir pada 12:09:10.325005\n",
            "\n",
            "Evaluating batch ke-5 dimulai pada 12:09:10.325249\n",
            "\n",
            "Evaluating batch ke-5 berakhir pada 12:09:10.383271\n",
            "\n",
            "Evaluating batch ke-6 dimulai pada 12:09:10.383488\n",
            "\n",
            "Evaluating batch ke-6 berakhir pada 12:09:10.447857\n",
            "\n",
            "Evaluating batch ke-7 dimulai pada 12:09:10.448203\n",
            "\n",
            "Evaluating batch ke-7 berakhir pada 12:09:10.498633\n",
            "\n",
            "Evaluating batch ke-8 dimulai pada 12:09:10.500687\n",
            "\n",
            "Evaluating batch ke-8 berakhir pada 12:09:10.550146\n",
            "\n",
            "Evaluating batch ke-9 dimulai pada 12:09:10.550392\n",
            "\n",
            "Evaluating batch ke-9 berakhir pada 12:09:10.590347\n",
            "\n",
            "Evaluating batch ke-10 dimulai pada 12:09:10.590576\n",
            "\n",
            "Evaluating batch ke-10 berakhir pada 12:09:10.633738\n",
            "\n",
            "Evaluating batch ke-11 dimulai pada 12:09:10.633990\n",
            "\n",
            "Evaluating batch ke-11 berakhir pada 12:09:10.662388\n",
            "Berakhir epoch ke-2; pada waktu 12:09:10.664178\n",
            "46/46 [==============================] - 10s 208ms/step - loss: 0.6300 - accuracy: 0.7143 - val_loss: 0.5033 - val_accuracy: 0.7283\n",
            "Dimulai epoch ke-3; pada waktu 12:09:10.666999\n",
            "Epoch 4/10\n",
            "\n",
            "Training batch ke-0 dimulai pada 12:09:10.667208\n",
            "Training batch ke-0 berakhir pada 12:09:10.883644\n",
            " 1/46 [..............................] - ETA: 0s - loss: 0.6628 - accuracy: 0.7500\n",
            "Training batch ke-1 dimulai pada 12:09:10.885636\n",
            "Training batch ke-1 berakhir pada 12:09:11.112455\n",
            " 2/46 [>.............................] - ETA: 5s - loss: 0.5371 - accuracy: 0.7812\n",
            "Training batch ke-2 dimulai pada 12:09:11.114227\n",
            "Training batch ke-2 berakhir pada 12:09:11.342707\n",
            " 3/46 [>.............................] - ETA: 6s - loss: 0.4819 - accuracy: 0.8021\n",
            "Training batch ke-3 dimulai pada 12:09:11.343941\n",
            "Training batch ke-3 berakhir pada 12:09:11.561436\n",
            " 4/46 [=>............................] - ETA: 7s - loss: 0.4860 - accuracy: 0.8047\n",
            "Training batch ke-4 dimulai pada 12:09:11.562742\n",
            "Training batch ke-4 berakhir pada 12:09:11.809358\n",
            " 5/46 [==>...........................] - ETA: 7s - loss: 0.5051 - accuracy: 0.8062\n",
            "Training batch ke-5 dimulai pada 12:09:11.810592\n",
            "Training batch ke-5 berakhir pada 12:09:12.042248\n",
            " 6/46 [==>...........................] - ETA: 7s - loss: 0.4863 - accuracy: 0.8125\n",
            "Training batch ke-6 dimulai pada 12:09:12.048139\n",
            "Training batch ke-6 berakhir pada 12:09:12.299776\n",
            " 7/46 [===>..........................] - ETA: 7s - loss: 0.4800 - accuracy: 0.8170\n",
            "Training batch ke-7 dimulai pada 12:09:12.301957\n",
            "Training batch ke-7 berakhir pada 12:09:12.523310\n",
            " 8/46 [====>.........................] - ETA: 7s - loss: 0.4648 - accuracy: 0.8203\n",
            "Training batch ke-8 dimulai pada 12:09:12.524986\n",
            "Training batch ke-8 berakhir pada 12:09:12.756388\n",
            " 9/46 [====>.........................] - ETA: 7s - loss: 0.4570 - accuracy: 0.8229\n",
            "Training batch ke-9 dimulai pada 12:09:12.757674\n",
            "Training batch ke-9 berakhir pada 12:09:12.982347\n",
            "10/46 [=====>........................] - ETA: 7s - loss: 0.4472 - accuracy: 0.8219\n",
            "Training batch ke-10 dimulai pada 12:09:12.984258\n",
            "Training batch ke-10 berakhir pada 12:09:13.239525\n",
            "11/46 [======>.......................] - ETA: 7s - loss: 0.4576 - accuracy: 0.8125\n",
            "Training batch ke-11 dimulai pada 12:09:13.243226\n",
            "Training batch ke-11 berakhir pada 12:09:13.473582\n",
            "12/46 [======>.......................] - ETA: 7s - loss: 0.4506 - accuracy: 0.8099\n",
            "Training batch ke-12 dimulai pada 12:09:13.475733\n",
            "Training batch ke-12 berakhir pada 12:09:13.700446\n",
            "13/46 [=======>......................] - ETA: 7s - loss: 0.4751 - accuracy: 0.7981\n",
            "Training batch ke-13 dimulai pada 12:09:13.702301\n",
            "Training batch ke-13 berakhir pada 12:09:13.923498\n",
            "14/46 [========>.....................] - ETA: 6s - loss: 0.4742 - accuracy: 0.7969\n",
            "Training batch ke-14 dimulai pada 12:09:13.925472\n",
            "Training batch ke-14 berakhir pada 12:09:14.138260\n",
            "15/46 [========>.....................] - ETA: 6s - loss: 0.4769 - accuracy: 0.8000\n",
            "Training batch ke-15 dimulai pada 12:09:14.139452\n",
            "Training batch ke-15 berakhir pada 12:09:14.353359\n",
            "16/46 [=========>....................] - ETA: 6s - loss: 0.4664 - accuracy: 0.8047\n",
            "Training batch ke-16 dimulai pada 12:09:14.355730\n",
            "Training batch ke-16 berakhir pada 12:09:14.562507\n",
            "17/46 [==========>...................] - ETA: 6s - loss: 0.4661 - accuracy: 0.8051\n",
            "Training batch ke-17 dimulai pada 12:09:14.563853\n",
            "Training batch ke-17 berakhir pada 12:09:14.771847\n",
            "18/46 [==========>...................] - ETA: 6s - loss: 0.4659 - accuracy: 0.8073\n",
            "Training batch ke-18 dimulai pada 12:09:14.773243\n",
            "Training batch ke-18 berakhir pada 12:09:14.987828\n",
            "19/46 [===========>..................] - ETA: 5s - loss: 0.4651 - accuracy: 0.8043\n",
            "Training batch ke-19 dimulai pada 12:09:14.989204\n",
            "Training batch ke-19 berakhir pada 12:09:15.208378\n",
            "20/46 [============>.................] - ETA: 5s - loss: 0.4612 - accuracy: 0.8109\n",
            "Training batch ke-20 dimulai pada 12:09:15.210399\n",
            "Training batch ke-20 berakhir pada 12:09:15.437528\n",
            "21/46 [============>.................] - ETA: 5s - loss: 0.4570 - accuracy: 0.8155\n",
            "Training batch ke-21 dimulai pada 12:09:15.438923\n",
            "Training batch ke-21 berakhir pada 12:09:15.668139\n",
            "22/46 [=============>................] - ETA: 5s - loss: 0.4596 - accuracy: 0.8168\n",
            "Training batch ke-22 dimulai pada 12:09:15.669360\n",
            "Training batch ke-22 berakhir pada 12:09:15.883693\n",
            "23/46 [==============>...............] - ETA: 5s - loss: 0.4594 - accuracy: 0.8179\n",
            "Training batch ke-23 dimulai pada 12:09:15.884943\n",
            "Training batch ke-23 berakhir pada 12:09:16.103355\n",
            "24/46 [==============>...............] - ETA: 4s - loss: 0.4550 - accuracy: 0.8203\n",
            "Training batch ke-24 dimulai pada 12:09:16.105107\n",
            "Training batch ke-24 berakhir pada 12:09:16.317939\n",
            "25/46 [===============>..............] - ETA: 4s - loss: 0.4525 - accuracy: 0.8213\n",
            "Training batch ke-25 dimulai pada 12:09:16.319587\n",
            "Training batch ke-25 berakhir pada 12:09:16.516852\n",
            "26/46 [===============>..............] - ETA: 4s - loss: 0.4550 - accuracy: 0.8209\n",
            "Training batch ke-26 dimulai pada 12:09:16.518216\n",
            "Training batch ke-26 berakhir pada 12:09:16.723607\n",
            "27/46 [================>.............] - ETA: 4s - loss: 0.4533 - accuracy: 0.8229\n",
            "Training batch ke-27 dimulai pada 12:09:16.725648\n",
            "Training batch ke-27 berakhir pada 12:09:16.926786\n",
            "28/46 [=================>............] - ETA: 3s - loss: 0.4489 - accuracy: 0.8248\n",
            "Training batch ke-28 dimulai pada 12:09:16.928749\n",
            "Training batch ke-28 berakhir pada 12:09:17.146796\n",
            "29/46 [=================>............] - ETA: 3s - loss: 0.4488 - accuracy: 0.8265\n",
            "Training batch ke-29 dimulai pada 12:09:17.147988\n",
            "Training batch ke-29 berakhir pada 12:09:17.358736\n",
            "30/46 [==================>...........] - ETA: 3s - loss: 0.4449 - accuracy: 0.8313\n",
            "Training batch ke-30 dimulai pada 12:09:17.360151\n",
            "Training batch ke-30 berakhir pada 12:09:17.569434\n",
            "31/46 [===================>..........] - ETA: 3s - loss: 0.4462 - accuracy: 0.8296\n",
            "Training batch ke-31 dimulai pada 12:09:17.570804\n",
            "Training batch ke-31 berakhir pada 12:09:17.782481\n",
            "32/46 [===================>..........] - ETA: 3s - loss: 0.4457 - accuracy: 0.8301\n",
            "Training batch ke-32 dimulai pada 12:09:17.783641\n",
            "Training batch ke-32 berakhir pada 12:09:17.982715\n",
            "33/46 [====================>.........] - ETA: 2s - loss: 0.4435 - accuracy: 0.8314\n",
            "Training batch ke-33 dimulai pada 12:09:17.984186\n",
            "Training batch ke-33 berakhir pada 12:09:18.192621\n",
            "34/46 [=====================>........] - ETA: 2s - loss: 0.4389 - accuracy: 0.8346\n",
            "Training batch ke-34 dimulai pada 12:09:18.195630\n",
            "Training batch ke-34 berakhir pada 12:09:18.404809\n",
            "35/46 [=====================>........] - ETA: 2s - loss: 0.4413 - accuracy: 0.8330\n",
            "Training batch ke-35 dimulai pada 12:09:18.406322\n",
            "Training batch ke-35 berakhir pada 12:09:18.617653\n",
            "36/46 [======================>.......] - ETA: 2s - loss: 0.4401 - accuracy: 0.8325\n",
            "Training batch ke-36 dimulai pada 12:09:18.619313\n",
            "Training batch ke-36 berakhir pada 12:09:18.818336\n",
            "37/46 [=======================>......] - ETA: 1s - loss: 0.4492 - accuracy: 0.8277\n",
            "Training batch ke-37 dimulai pada 12:09:18.819718\n",
            "Training batch ke-37 berakhir pada 12:09:19.016171\n",
            "38/46 [=======================>......] - ETA: 1s - loss: 0.4499 - accuracy: 0.8257\n",
            "Training batch ke-38 dimulai pada 12:09:19.018013\n",
            "Training batch ke-38 berakhir pada 12:09:19.220052\n",
            "39/46 [========================>.....] - ETA: 1s - loss: 0.4491 - accuracy: 0.8237\n",
            "Training batch ke-39 dimulai pada 12:09:19.221360\n",
            "Training batch ke-39 berakhir pada 12:09:19.420608\n",
            "40/46 [=========================>....] - ETA: 1s - loss: 0.4558 - accuracy: 0.8227\n",
            "Training batch ke-40 dimulai pada 12:09:19.421835\n",
            "Training batch ke-40 berakhir pada 12:09:19.614211\n",
            "41/46 [=========================>....] - ETA: 1s - loss: 0.4594 - accuracy: 0.8209\n",
            "Training batch ke-41 dimulai pada 12:09:19.615300\n",
            "Training batch ke-41 berakhir pada 12:09:19.809402\n",
            "42/46 [==========================>...] - ETA: 0s - loss: 0.4595 - accuracy: 0.8199\n",
            "Training batch ke-42 dimulai pada 12:09:19.810715\n",
            "Training batch ke-42 berakhir pada 12:09:20.003768\n",
            "43/46 [===========================>..] - ETA: 0s - loss: 0.4644 - accuracy: 0.8190\n",
            "Training batch ke-43 dimulai pada 12:09:20.004902\n",
            "Training batch ke-43 berakhir pada 12:09:20.195687\n",
            "44/46 [===========================>..] - ETA: 0s - loss: 0.4657 - accuracy: 0.8196\n",
            "Training batch ke-44 dimulai pada 12:09:20.196961\n",
            "Training batch ke-44 berakhir pada 12:09:20.396401\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.4680 - accuracy: 0.8201\n",
            "Training batch ke-45 dimulai pada 12:09:20.397946\n",
            "Training batch ke-45 berakhir pada 12:09:20.583077\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.4734 - accuracy: 0.8190\n",
            "Evaluating batch ke-0 dimulai pada 12:09:20.603460\n",
            "\n",
            "Evaluating batch ke-0 berakhir pada 12:09:20.645084\n",
            "\n",
            "Evaluating batch ke-1 dimulai pada 12:09:20.645273\n",
            "\n",
            "Evaluating batch ke-1 berakhir pada 12:09:20.682586\n",
            "\n",
            "Evaluating batch ke-2 dimulai pada 12:09:20.682782\n",
            "\n",
            "Evaluating batch ke-2 berakhir pada 12:09:20.721238\n",
            "\n",
            "Evaluating batch ke-3 dimulai pada 12:09:20.721443\n",
            "\n",
            "Evaluating batch ke-3 berakhir pada 12:09:20.759646\n",
            "\n",
            "Evaluating batch ke-4 dimulai pada 12:09:20.759858\n",
            "\n",
            "Evaluating batch ke-4 berakhir pada 12:09:20.801725\n",
            "\n",
            "Evaluating batch ke-5 dimulai pada 12:09:20.801954\n",
            "\n",
            "Evaluating batch ke-5 berakhir pada 12:09:20.842726\n",
            "\n",
            "Evaluating batch ke-6 dimulai pada 12:09:20.842956\n",
            "\n",
            "Evaluating batch ke-6 berakhir pada 12:09:20.881877\n",
            "\n",
            "Evaluating batch ke-7 dimulai pada 12:09:20.882114\n",
            "\n",
            "Evaluating batch ke-7 berakhir pada 12:09:20.925034\n",
            "\n",
            "Evaluating batch ke-8 dimulai pada 12:09:20.925232\n",
            "\n",
            "Evaluating batch ke-8 berakhir pada 12:09:20.972775\n",
            "\n",
            "Evaluating batch ke-9 dimulai pada 12:09:20.973056\n",
            "\n",
            "Evaluating batch ke-9 berakhir pada 12:09:21.018424\n",
            "\n",
            "Evaluating batch ke-10 dimulai pada 12:09:21.018632\n",
            "\n",
            "Evaluating batch ke-10 berakhir pada 12:09:21.061509\n",
            "\n",
            "Evaluating batch ke-11 dimulai pada 12:09:21.061710\n",
            "\n",
            "Evaluating batch ke-11 berakhir pada 12:09:21.087756\n",
            "Berakhir epoch ke-3; pada waktu 12:09:21.089599\n",
            "46/46 [==============================] - 10s 222ms/step - loss: 0.4734 - accuracy: 0.8190 - val_loss: 0.6079 - val_accuracy: 0.8071\n",
            "Dimulai epoch ke-4; pada waktu 12:09:21.092193\n",
            "Epoch 5/10\n",
            "\n",
            "Training batch ke-0 dimulai pada 12:09:21.092408\n",
            "Training batch ke-0 berakhir pada 12:09:21.287424\n",
            " 1/46 [..............................] - ETA: 0s - loss: 0.3464 - accuracy: 0.8750\n",
            "Training batch ke-1 dimulai pada 12:09:21.288995\n",
            "Training batch ke-1 berakhir pada 12:09:21.483978\n",
            " 2/46 [>.............................] - ETA: 4s - loss: 0.3986 - accuracy: 0.7969\n",
            "Training batch ke-2 dimulai pada 12:09:21.485586\n",
            "Training batch ke-2 berakhir pada 12:09:21.677673\n",
            " 3/46 [>.............................] - ETA: 5s - loss: 0.3762 - accuracy: 0.8438\n",
            "Training batch ke-3 dimulai pada 12:09:21.678937\n",
            "Training batch ke-3 berakhir pada 12:09:21.875863\n",
            " 4/46 [=>............................] - ETA: 6s - loss: 0.3843 - accuracy: 0.8438\n",
            "Training batch ke-4 dimulai pada 12:09:21.877001\n",
            "Training batch ke-4 berakhir pada 12:09:22.064412\n",
            " 5/46 [==>...........................] - ETA: 6s - loss: 0.4044 - accuracy: 0.8375\n",
            "Training batch ke-5 dimulai pada 12:09:22.065920\n",
            "Training batch ke-5 berakhir pada 12:09:22.260694\n",
            " 6/46 [==>...........................] - ETA: 6s - loss: 0.3886 - accuracy: 0.8490\n",
            "Training batch ke-6 dimulai pada 12:09:22.261911\n",
            "Training batch ke-6 berakhir pada 12:09:22.462296\n",
            " 7/46 [===>..........................] - ETA: 6s - loss: 0.4054 - accuracy: 0.8616\n",
            "Training batch ke-7 dimulai pada 12:09:22.463643\n",
            "Training batch ke-7 berakhir pada 12:09:22.653197\n",
            " 8/46 [====>.........................] - ETA: 6s - loss: 0.3985 - accuracy: 0.8633\n",
            "Training batch ke-8 dimulai pada 12:09:22.654479\n",
            "Training batch ke-8 berakhir pada 12:09:22.847761\n",
            " 9/46 [====>.........................] - ETA: 6s - loss: 0.3867 - accuracy: 0.8715\n",
            "Training batch ke-9 dimulai pada 12:09:22.849056\n",
            "Training batch ke-9 berakhir pada 12:09:23.042492\n",
            "10/46 [=====>........................] - ETA: 6s - loss: 0.3894 - accuracy: 0.8687\n",
            "Training batch ke-10 dimulai pada 12:09:23.043814\n",
            "Training batch ke-10 berakhir pada 12:09:23.235632\n",
            "11/46 [======>.......................] - ETA: 6s - loss: 0.3851 - accuracy: 0.8722\n",
            "Training batch ke-11 dimulai pada 12:09:23.236865\n",
            "Training batch ke-11 berakhir pada 12:09:23.431446\n",
            "12/46 [======>.......................] - ETA: 6s - loss: 0.3698 - accuracy: 0.8802\n",
            "Training batch ke-12 dimulai pada 12:09:23.432877\n",
            "Training batch ke-12 berakhir pada 12:09:23.640814\n",
            "13/46 [=======>......................] - ETA: 5s - loss: 0.3644 - accuracy: 0.8846\n",
            "Training batch ke-13 dimulai pada 12:09:23.643108\n",
            "Training batch ke-13 berakhir pada 12:09:23.830117\n",
            "14/46 [========>.....................] - ETA: 5s - loss: 0.3566 - accuracy: 0.8906\n",
            "Training batch ke-14 dimulai pada 12:09:23.831556\n",
            "Training batch ke-14 berakhir pada 12:09:24.020500\n",
            "15/46 [========>.....................] - ETA: 5s - loss: 0.3517 - accuracy: 0.8938\n",
            "Training batch ke-15 dimulai pada 12:09:24.021666\n",
            "Training batch ke-15 berakhir pada 12:09:24.213957\n",
            "16/46 [=========>....................] - ETA: 5s - loss: 0.3523 - accuracy: 0.8926\n",
            "Training batch ke-16 dimulai pada 12:09:24.215107\n",
            "Training batch ke-16 berakhir pada 12:09:24.405409\n",
            "17/46 [==========>...................] - ETA: 5s - loss: 0.3447 - accuracy: 0.8971\n",
            "Training batch ke-17 dimulai pada 12:09:24.406632\n",
            "Training batch ke-17 berakhir pada 12:09:24.605282\n",
            "18/46 [==========>...................] - ETA: 5s - loss: 0.3445 - accuracy: 0.8976\n",
            "Training batch ke-18 dimulai pada 12:09:24.606610\n",
            "Training batch ke-18 berakhir pada 12:09:24.796139\n",
            "19/46 [===========>..................] - ETA: 4s - loss: 0.3457 - accuracy: 0.8964\n",
            "Training batch ke-19 dimulai pada 12:09:24.797364\n",
            "Training batch ke-19 berakhir pada 12:09:24.990670\n",
            "20/46 [============>.................] - ETA: 4s - loss: 0.3426 - accuracy: 0.8953\n",
            "Training batch ke-20 dimulai pada 12:09:24.992334\n",
            "Training batch ke-20 berakhir pada 12:09:25.181708\n",
            "21/46 [============>.................] - ETA: 4s - loss: 0.3421 - accuracy: 0.8929\n",
            "Training batch ke-21 dimulai pada 12:09:25.182957\n",
            "Training batch ke-21 berakhir pada 12:09:25.377709\n",
            "22/46 [=============>................] - ETA: 4s - loss: 0.3358 - accuracy: 0.8949\n",
            "Training batch ke-22 dimulai pada 12:09:25.378990\n",
            "Training batch ke-22 berakhir pada 12:09:25.577150\n",
            "23/46 [==============>...............] - ETA: 4s - loss: 0.3360 - accuracy: 0.8954\n",
            "Training batch ke-23 dimulai pada 12:09:25.578363\n",
            "Training batch ke-23 berakhir pada 12:09:25.768844\n",
            "24/46 [==============>...............] - ETA: 4s - loss: 0.3327 - accuracy: 0.8971\n",
            "Training batch ke-24 dimulai pada 12:09:25.770386\n",
            "Training batch ke-24 berakhir pada 12:09:25.961828\n",
            "25/46 [===============>..............] - ETA: 3s - loss: 0.3251 - accuracy: 0.8988\n",
            "Training batch ke-25 dimulai pada 12:09:25.963131\n",
            "Training batch ke-25 berakhir pada 12:09:26.152970\n",
            "26/46 [===============>..............] - ETA: 3s - loss: 0.3210 - accuracy: 0.8990\n",
            "Training batch ke-26 dimulai pada 12:09:26.154223\n",
            "Training batch ke-26 berakhir pada 12:09:26.347577\n",
            "27/46 [================>.............] - ETA: 3s - loss: 0.3173 - accuracy: 0.9005\n",
            "Training batch ke-27 dimulai pada 12:09:26.348795\n",
            "Training batch ke-27 berakhir pada 12:09:26.553793\n",
            "28/46 [=================>............] - ETA: 3s - loss: 0.3185 - accuracy: 0.8984\n",
            "Training batch ke-28 dimulai pada 12:09:26.554955\n",
            "Training batch ke-28 berakhir pada 12:09:26.747600\n",
            "29/46 [=================>............] - ETA: 3s - loss: 0.3184 - accuracy: 0.8966\n",
            "Training batch ke-29 dimulai pada 12:09:26.749512\n",
            "Training batch ke-29 berakhir pada 12:09:26.941292\n",
            "30/46 [==================>...........] - ETA: 3s - loss: 0.3166 - accuracy: 0.8969\n",
            "Training batch ke-30 dimulai pada 12:09:26.942573\n",
            "Training batch ke-30 berakhir pada 12:09:27.178543\n",
            "31/46 [===================>..........] - ETA: 2s - loss: 0.3143 - accuracy: 0.8962\n",
            "Training batch ke-31 dimulai pada 12:09:27.187619\n",
            "Training batch ke-31 berakhir pada 12:09:28.043857\n",
            "32/46 [===================>..........] - ETA: 2s - loss: 0.3101 - accuracy: 0.8975\n",
            "Training batch ke-32 dimulai pada 12:09:28.050199\n",
            "Training batch ke-32 berakhir pada 12:09:28.421776\n",
            "33/46 [====================>.........] - ETA: 2s - loss: 0.3162 - accuracy: 0.8930\n",
            "Training batch ke-33 dimulai pada 12:09:28.427909\n",
            "Training batch ke-33 berakhir pada 12:09:28.773649\n",
            "34/46 [=====================>........] - ETA: 2s - loss: 0.3139 - accuracy: 0.8925\n",
            "Training batch ke-34 dimulai pada 12:09:28.779679\n",
            "Training batch ke-34 berakhir pada 12:09:29.124833\n",
            "35/46 [=====================>........] - ETA: 2s - loss: 0.3115 - accuracy: 0.8920\n",
            "Training batch ke-35 dimulai pada 12:09:29.131732\n",
            "Training batch ke-35 berakhir pada 12:09:29.510001\n",
            "36/46 [======================>.......] - ETA: 2s - loss: 0.3072 - accuracy: 0.8941\n",
            "Training batch ke-36 dimulai pada 12:09:29.516456\n",
            "Training batch ke-36 berakhir pada 12:09:29.885065\n",
            "37/46 [=======================>......] - ETA: 2s - loss: 0.3054 - accuracy: 0.8936\n",
            "Training batch ke-37 dimulai pada 12:09:29.890887\n",
            "Training batch ke-37 berakhir pada 12:09:30.236156\n",
            "38/46 [=======================>......] - ETA: 1s - loss: 0.3036 - accuracy: 0.8939\n",
            "Training batch ke-38 dimulai pada 12:09:30.243114\n",
            "Training batch ke-38 berakhir pada 12:09:30.601105\n",
            "39/46 [========================>.....] - ETA: 1s - loss: 0.2991 - accuracy: 0.8958\n",
            "Training batch ke-39 dimulai pada 12:09:30.605857\n",
            "Training batch ke-39 berakhir pada 12:09:30.958397\n",
            "40/46 [=========================>....] - ETA: 1s - loss: 0.2964 - accuracy: 0.8961\n",
            "Training batch ke-40 dimulai pada 12:09:30.964670\n",
            "Training batch ke-40 berakhir pada 12:09:31.305252\n",
            "41/46 [=========================>....] - ETA: 1s - loss: 0.2949 - accuracy: 0.8941\n",
            "Training batch ke-41 dimulai pada 12:09:31.309857\n",
            "Training batch ke-41 berakhir pada 12:09:31.659865\n",
            "42/46 [==========================>...] - ETA: 0s - loss: 0.2944 - accuracy: 0.8936\n",
            "Training batch ke-42 dimulai pada 12:09:31.668040\n",
            "Training batch ke-42 berakhir pada 12:09:32.016940\n",
            "43/46 [===========================>..] - ETA: 0s - loss: 0.2943 - accuracy: 0.8946\n",
            "Training batch ke-43 dimulai pada 12:09:32.023192\n",
            "Training batch ke-43 berakhir pada 12:09:32.364519\n",
            "44/46 [===========================>..] - ETA: 0s - loss: 0.2922 - accuracy: 0.8970\n",
            "Training batch ke-44 dimulai pada 12:09:32.370766\n",
            "Training batch ke-44 berakhir pada 12:09:32.708243\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.2912 - accuracy: 0.8972\n",
            "Training batch ke-45 dimulai pada 12:09:32.714134\n",
            "Training batch ke-45 berakhir pada 12:09:33.052589\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.2905 - accuracy: 0.8980\n",
            "Evaluating batch ke-0 dimulai pada 12:09:33.081125\n",
            "\n",
            "Evaluating batch ke-0 berakhir pada 12:09:33.153267\n",
            "\n",
            "Evaluating batch ke-1 dimulai pada 12:09:33.153513\n",
            "\n",
            "Evaluating batch ke-1 berakhir pada 12:09:33.220508\n",
            "\n",
            "Evaluating batch ke-2 dimulai pada 12:09:33.220708\n",
            "\n",
            "Evaluating batch ke-2 berakhir pada 12:09:33.293475\n",
            "\n",
            "Evaluating batch ke-3 dimulai pada 12:09:33.293682\n",
            "\n",
            "Evaluating batch ke-3 berakhir pada 12:09:33.360554\n",
            "\n",
            "Evaluating batch ke-4 dimulai pada 12:09:33.360752\n",
            "\n",
            "Evaluating batch ke-4 berakhir pada 12:09:33.427745\n",
            "\n",
            "Evaluating batch ke-5 dimulai pada 12:09:33.427982\n",
            "\n",
            "Evaluating batch ke-5 berakhir pada 12:09:33.494439\n",
            "\n",
            "Evaluating batch ke-6 dimulai pada 12:09:33.494643\n",
            "\n",
            "Evaluating batch ke-6 berakhir pada 12:09:33.570968\n",
            "\n",
            "Evaluating batch ke-7 dimulai pada 12:09:33.571178\n",
            "\n",
            "Evaluating batch ke-7 berakhir pada 12:09:33.638659\n",
            "\n",
            "Evaluating batch ke-8 dimulai pada 12:09:33.638871\n",
            "\n",
            "Evaluating batch ke-8 berakhir pada 12:09:33.705447\n",
            "\n",
            "Evaluating batch ke-9 dimulai pada 12:09:33.705665\n",
            "\n",
            "Evaluating batch ke-9 berakhir pada 12:09:33.772541\n",
            "\n",
            "Evaluating batch ke-10 dimulai pada 12:09:33.772763\n",
            "\n",
            "Evaluating batch ke-10 berakhir pada 12:09:33.859706\n",
            "\n",
            "Evaluating batch ke-11 dimulai pada 12:09:33.859960\n",
            "\n",
            "Evaluating batch ke-11 berakhir pada 12:09:33.904757\n",
            "Berakhir epoch ke-4; pada waktu 12:09:33.906711\n",
            "46/46 [==============================] - 13s 274ms/step - loss: 0.2905 - accuracy: 0.8980 - val_loss: 0.3708 - val_accuracy: 0.8995\n",
            "Dimulai epoch ke-5; pada waktu 12:09:33.914729\n",
            "Epoch 6/10\n",
            "\n",
            "Training batch ke-0 dimulai pada 12:09:33.915586\n",
            "Training batch ke-0 berakhir pada 12:09:34.261766\n",
            " 1/46 [..............................] - ETA: 0s - loss: 0.1520 - accuracy: 0.9688\n",
            "Training batch ke-1 dimulai pada 12:09:34.267683\n",
            "Training batch ke-1 berakhir pada 12:09:34.605797\n",
            " 2/46 [>.............................] - ETA: 7s - loss: 0.2487 - accuracy: 0.9062\n",
            "Training batch ke-2 dimulai pada 12:09:34.612702\n",
            "Training batch ke-2 berakhir pada 12:09:34.973191\n",
            " 3/46 [>.............................] - ETA: 10s - loss: 0.2343 - accuracy: 0.9271\n",
            "Training batch ke-3 dimulai pada 12:09:34.979185\n",
            "Training batch ke-3 berakhir pada 12:09:35.325004\n",
            " 4/46 [=>............................] - ETA: 11s - loss: 0.2363 - accuracy: 0.9297\n",
            "Training batch ke-4 dimulai pada 12:09:35.330933\n",
            "Training batch ke-4 berakhir pada 12:09:35.678450\n",
            " 5/46 [==>...........................] - ETA: 11s - loss: 0.2213 - accuracy: 0.9312\n",
            "Training batch ke-5 dimulai pada 12:09:35.684715\n",
            "Training batch ke-5 berakhir pada 12:09:35.938529\n",
            " 6/46 [==>...........................] - ETA: 11s - loss: 0.2261 - accuracy: 0.9271\n",
            "Training batch ke-6 dimulai pada 12:09:35.941065\n",
            "Training batch ke-6 berakhir pada 12:09:36.127317\n",
            " 7/46 [===>..........................] - ETA: 10s - loss: 0.2207 - accuracy: 0.9330\n",
            "Training batch ke-7 dimulai pada 12:09:36.128719\n",
            "Training batch ke-7 berakhir pada 12:09:36.319502\n",
            " 8/46 [====>.........................] - ETA: 9s - loss: 0.2227 - accuracy: 0.9297 \n",
            "Training batch ke-8 dimulai pada 12:09:36.320733\n",
            "Training batch ke-8 berakhir pada 12:09:36.510876\n",
            " 9/46 [====>.........................] - ETA: 9s - loss: 0.2229 - accuracy: 0.9306\n",
            "Training batch ke-9 dimulai pada 12:09:36.512127\n",
            "Training batch ke-9 berakhir pada 12:09:36.703602\n",
            "10/46 [=====>........................] - ETA: 8s - loss: 0.2178 - accuracy: 0.9281\n",
            "Training batch ke-10 dimulai pada 12:09:36.704816\n",
            "Training batch ke-10 berakhir pada 12:09:36.902276\n",
            "11/46 [======>.......................] - ETA: 8s - loss: 0.2092 - accuracy: 0.9318\n",
            "Training batch ke-11 dimulai pada 12:09:36.903516\n",
            "Training batch ke-11 berakhir pada 12:09:37.093353\n",
            "12/46 [======>.......................] - ETA: 8s - loss: 0.2084 - accuracy: 0.9297\n",
            "Training batch ke-12 dimulai pada 12:09:37.094601\n",
            "Training batch ke-12 berakhir pada 12:09:37.287984\n",
            "13/46 [=======>......................] - ETA: 7s - loss: 0.2016 - accuracy: 0.9303\n",
            "Training batch ke-13 dimulai pada 12:09:37.289253\n",
            "Training batch ke-13 berakhir pada 12:09:37.483140\n",
            "14/46 [========>.....................] - ETA: 7s - loss: 0.1976 - accuracy: 0.9330\n",
            "Training batch ke-14 dimulai pada 12:09:37.484386\n",
            "Training batch ke-14 berakhir pada 12:09:37.678377\n",
            "15/46 [========>.....................] - ETA: 7s - loss: 0.1950 - accuracy: 0.9333\n",
            "Training batch ke-15 dimulai pada 12:09:37.679613\n",
            "Training batch ke-15 berakhir pada 12:09:37.872593\n",
            "16/46 [=========>....................] - ETA: 6s - loss: 0.1961 - accuracy: 0.9355\n",
            "Training batch ke-16 dimulai pada 12:09:37.873794\n",
            "Training batch ke-16 berakhir pada 12:09:38.082500\n",
            "17/46 [==========>...................] - ETA: 6s - loss: 0.1930 - accuracy: 0.9375\n",
            "Training batch ke-17 dimulai pada 12:09:38.084179\n",
            "Training batch ke-17 berakhir pada 12:09:38.275678\n",
            "18/46 [==========>...................] - ETA: 6s - loss: 0.1927 - accuracy: 0.9358\n",
            "Training batch ke-18 dimulai pada 12:09:38.277105\n",
            "Training batch ke-18 berakhir pada 12:09:38.476668\n",
            "19/46 [===========>..................] - ETA: 5s - loss: 0.1901 - accuracy: 0.9375\n",
            "Training batch ke-19 dimulai pada 12:09:38.477969\n",
            "Training batch ke-19 berakhir pada 12:09:38.675388\n",
            "20/46 [============>.................] - ETA: 5s - loss: 0.1883 - accuracy: 0.9391\n",
            "Training batch ke-20 dimulai pada 12:09:38.676662\n",
            "Training batch ke-20 berakhir pada 12:09:38.870723\n",
            "21/46 [============>.................] - ETA: 5s - loss: 0.1858 - accuracy: 0.9420\n",
            "Training batch ke-21 dimulai pada 12:09:38.872057\n",
            "Training batch ke-21 berakhir pada 12:09:39.084659\n",
            "22/46 [=============>................] - ETA: 5s - loss: 0.1835 - accuracy: 0.9432\n",
            "Training batch ke-22 dimulai pada 12:09:39.085969\n",
            "Training batch ke-22 berakhir pada 12:09:39.280457\n",
            "23/46 [==============>...............] - ETA: 5s - loss: 0.1821 - accuracy: 0.9443\n",
            "Training batch ke-23 dimulai pada 12:09:39.281678\n",
            "Training batch ke-23 berakhir pada 12:09:39.481139\n",
            "24/46 [==============>...............] - ETA: 4s - loss: 0.1792 - accuracy: 0.9453\n",
            "Training batch ke-24 dimulai pada 12:09:39.482488\n",
            "Training batch ke-24 berakhir pada 12:09:39.679182\n",
            "25/46 [===============>..............] - ETA: 4s - loss: 0.1777 - accuracy: 0.9438\n",
            "Training batch ke-25 dimulai pada 12:09:39.680875\n",
            "Training batch ke-25 berakhir pada 12:09:39.879589\n",
            "26/46 [===============>..............] - ETA: 4s - loss: 0.1746 - accuracy: 0.9459\n",
            "Training batch ke-26 dimulai pada 12:09:39.880845\n",
            "Training batch ke-26 berakhir pada 12:09:40.093836\n",
            "27/46 [================>.............] - ETA: 4s - loss: 0.1718 - accuracy: 0.9456\n",
            "Training batch ke-27 dimulai pada 12:09:40.095186\n",
            "Training batch ke-27 berakhir pada 12:09:40.288829\n",
            "28/46 [=================>............] - ETA: 3s - loss: 0.1706 - accuracy: 0.9464\n",
            "Training batch ke-28 dimulai pada 12:09:40.290010\n",
            "Training batch ke-28 berakhir pada 12:09:40.481825\n",
            "29/46 [=================>............] - ETA: 3s - loss: 0.1667 - accuracy: 0.9483\n",
            "Training batch ke-29 dimulai pada 12:09:40.483856\n",
            "Training batch ke-29 berakhir pada 12:09:40.680273\n",
            "30/46 [==================>...........] - ETA: 3s - loss: 0.1650 - accuracy: 0.9479\n",
            "Training batch ke-30 dimulai pada 12:09:40.681571\n",
            "Training batch ke-30 berakhir pada 12:09:40.879709\n",
            "31/46 [===================>..........] - ETA: 3s - loss: 0.1732 - accuracy: 0.9466\n",
            "Training batch ke-31 dimulai pada 12:09:40.881004\n",
            "Training batch ke-31 berakhir pada 12:09:41.090369\n",
            "32/46 [===================>..........] - ETA: 2s - loss: 0.1745 - accuracy: 0.9453\n",
            "Training batch ke-32 dimulai pada 12:09:41.091573\n",
            "Training batch ke-32 berakhir pada 12:09:41.284975\n",
            "33/46 [====================>.........] - ETA: 2s - loss: 0.1736 - accuracy: 0.9451\n",
            "Training batch ke-33 dimulai pada 12:09:41.286471\n",
            "Training batch ke-33 berakhir pada 12:09:41.485351\n",
            "34/46 [=====================>........] - ETA: 2s - loss: 0.1711 - accuracy: 0.9458\n",
            "Training batch ke-34 dimulai pada 12:09:41.487101\n",
            "Training batch ke-34 berakhir pada 12:09:41.688318\n",
            "35/46 [=====================>........] - ETA: 2s - loss: 0.1689 - accuracy: 0.9473\n",
            "Training batch ke-35 dimulai pada 12:09:41.689671\n",
            "Training batch ke-35 berakhir pada 12:09:41.886523\n",
            "36/46 [======================>.......] - ETA: 2s - loss: 0.1685 - accuracy: 0.9470\n",
            "Training batch ke-36 dimulai pada 12:09:41.887779\n",
            "Training batch ke-36 berakhir pada 12:09:42.097109\n",
            "37/46 [=======================>......] - ETA: 1s - loss: 0.1662 - accuracy: 0.9485\n",
            "Training batch ke-37 dimulai pada 12:09:42.098969\n",
            "Training batch ke-37 berakhir pada 12:09:42.302181\n",
            "38/46 [=======================>......] - ETA: 1s - loss: 0.1647 - accuracy: 0.9490\n",
            "Training batch ke-38 dimulai pada 12:09:42.303641\n",
            "Training batch ke-38 berakhir pada 12:09:42.502796\n",
            "39/46 [========================>.....] - ETA: 1s - loss: 0.1635 - accuracy: 0.9503\n",
            "Training batch ke-39 dimulai pada 12:09:42.503952\n",
            "Training batch ke-39 berakhir pada 12:09:42.700940\n",
            "40/46 [=========================>....] - ETA: 1s - loss: 0.1614 - accuracy: 0.9508\n",
            "Training batch ke-40 dimulai pada 12:09:42.702281\n",
            "Training batch ke-40 berakhir pada 12:09:42.898334\n",
            "41/46 [=========================>....] - ETA: 1s - loss: 0.1590 - accuracy: 0.9512\n",
            "Training batch ke-41 dimulai pada 12:09:42.899605\n",
            "Training batch ke-41 berakhir pada 12:09:43.110270\n",
            "42/46 [==========================>...] - ETA: 0s - loss: 0.1565 - accuracy: 0.9524\n",
            "Training batch ke-42 dimulai pada 12:09:43.111544\n",
            "Training batch ke-42 berakhir pada 12:09:43.306830\n",
            "43/46 [===========================>..] - ETA: 0s - loss: 0.1542 - accuracy: 0.9535\n",
            "Training batch ke-43 dimulai pada 12:09:43.308084\n",
            "Training batch ke-43 berakhir pada 12:09:43.506972\n",
            "44/46 [===========================>..] - ETA: 0s - loss: 0.1539 - accuracy: 0.9531\n",
            "Training batch ke-44 dimulai pada 12:09:43.508275\n",
            "Training batch ke-44 berakhir pada 12:09:43.713357\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.1536 - accuracy: 0.9528\n",
            "Training batch ke-45 dimulai pada 12:09:43.714655\n",
            "Training batch ke-45 berakhir pada 12:09:43.909634\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.1548 - accuracy: 0.9517\n",
            "Evaluating batch ke-0 dimulai pada 12:09:43.929625\n",
            "\n",
            "Evaluating batch ke-0 berakhir pada 12:09:43.973226\n",
            "\n",
            "Evaluating batch ke-1 dimulai pada 12:09:43.973463\n",
            "\n",
            "Evaluating batch ke-1 berakhir pada 12:09:44.013601\n",
            "\n",
            "Evaluating batch ke-2 dimulai pada 12:09:44.013824\n",
            "\n",
            "Evaluating batch ke-2 berakhir pada 12:09:44.061709\n",
            "\n",
            "Evaluating batch ke-3 dimulai pada 12:09:44.061957\n",
            "\n",
            "Evaluating batch ke-3 berakhir pada 12:09:44.099509\n",
            "\n",
            "Evaluating batch ke-4 dimulai pada 12:09:44.099710\n",
            "\n",
            "Evaluating batch ke-4 berakhir pada 12:09:44.141593\n",
            "\n",
            "Evaluating batch ke-5 dimulai pada 12:09:44.141803\n",
            "\n",
            "Evaluating batch ke-5 berakhir pada 12:09:44.180620\n",
            "\n",
            "Evaluating batch ke-6 dimulai pada 12:09:44.180824\n",
            "\n",
            "Evaluating batch ke-6 berakhir pada 12:09:44.218534\n",
            "\n",
            "Evaluating batch ke-7 dimulai pada 12:09:44.218735\n",
            "\n",
            "Evaluating batch ke-7 berakhir pada 12:09:44.255568\n",
            "\n",
            "Evaluating batch ke-8 dimulai pada 12:09:44.255773\n",
            "\n",
            "Evaluating batch ke-8 berakhir pada 12:09:44.292723\n",
            "\n",
            "Evaluating batch ke-9 dimulai pada 12:09:44.292944\n",
            "\n",
            "Evaluating batch ke-9 berakhir pada 12:09:44.329605\n",
            "\n",
            "Evaluating batch ke-10 dimulai pada 12:09:44.329808\n",
            "\n",
            "Evaluating batch ke-10 berakhir pada 12:09:44.370595\n",
            "\n",
            "Evaluating batch ke-11 dimulai pada 12:09:44.370802\n",
            "\n",
            "Evaluating batch ke-11 berakhir pada 12:09:44.396045\n",
            "Berakhir epoch ke-5; pada waktu 12:09:44.397516\n",
            "46/46 [==============================] - 10s 220ms/step - loss: 0.1548 - accuracy: 0.9517 - val_loss: 0.2685 - val_accuracy: 0.9130\n",
            "Dimulai epoch ke-6; pada waktu 12:09:44.399657\n",
            "Epoch 7/10\n",
            "\n",
            "Training batch ke-0 dimulai pada 12:09:44.400009\n",
            "Training batch ke-0 berakhir pada 12:09:44.595199\n",
            " 1/46 [..............................] - ETA: 0s - loss: 0.0489 - accuracy: 1.0000\n",
            "Training batch ke-1 dimulai pada 12:09:44.596391\n",
            "Training batch ke-1 berakhir pada 12:09:44.791498\n",
            " 2/46 [>.............................] - ETA: 4s - loss: 0.0686 - accuracy: 0.9844\n",
            "Training batch ke-2 dimulai pada 12:09:44.792773\n",
            "Training batch ke-2 berakhir pada 12:09:44.984812\n",
            " 3/46 [>.............................] - ETA: 5s - loss: 0.0657 - accuracy: 0.9896\n",
            "Training batch ke-3 dimulai pada 12:09:44.986384\n",
            "Training batch ke-3 berakhir pada 12:09:45.192295\n",
            " 4/46 [=>............................] - ETA: 6s - loss: 0.0703 - accuracy: 0.9922\n",
            "Training batch ke-4 dimulai pada 12:09:45.194289\n",
            "Training batch ke-4 berakhir pada 12:09:45.385439\n",
            " 5/46 [==>...........................] - ETA: 6s - loss: 0.0745 - accuracy: 0.9875\n",
            "Training batch ke-5 dimulai pada 12:09:45.386618\n",
            "Training batch ke-5 berakhir pada 12:09:45.583452\n",
            " 6/46 [==>...........................] - ETA: 6s - loss: 0.0736 - accuracy: 0.9896\n",
            "Training batch ke-6 dimulai pada 12:09:45.585058\n",
            "Training batch ke-6 berakhir pada 12:09:45.784210\n",
            " 7/46 [===>..........................] - ETA: 6s - loss: 0.0772 - accuracy: 0.9911\n",
            "Training batch ke-7 dimulai pada 12:09:45.785474\n",
            "Training batch ke-7 berakhir pada 12:09:45.973601\n",
            " 8/46 [====>.........................] - ETA: 6s - loss: 0.0754 - accuracy: 0.9922\n",
            "Training batch ke-8 dimulai pada 12:09:45.974781\n",
            "Training batch ke-8 berakhir pada 12:09:46.176065\n",
            " 9/46 [====>.........................] - ETA: 6s - loss: 0.0763 - accuracy: 0.9931\n",
            "Training batch ke-9 dimulai pada 12:09:46.177471\n",
            "Training batch ke-9 berakhir pada 12:09:46.364667\n",
            "10/46 [=====>........................] - ETA: 6s - loss: 0.0817 - accuracy: 0.9844\n",
            "Training batch ke-10 dimulai pada 12:09:46.365876\n",
            "Training batch ke-10 berakhir pada 12:09:46.560226\n",
            "11/46 [======>.......................] - ETA: 6s - loss: 0.0912 - accuracy: 0.9801\n",
            "Training batch ke-11 dimulai pada 12:09:46.561479\n",
            "Training batch ke-11 berakhir pada 12:09:46.759139\n",
            "12/46 [======>.......................] - ETA: 6s - loss: 0.0886 - accuracy: 0.9792\n",
            "Training batch ke-12 dimulai pada 12:09:46.760343\n",
            "Training batch ke-12 berakhir pada 12:09:46.953506\n",
            "13/46 [=======>......................] - ETA: 5s - loss: 0.0869 - accuracy: 0.9808\n",
            "Training batch ke-13 dimulai pada 12:09:46.954757\n",
            "Training batch ke-13 berakhir pada 12:09:47.160693\n",
            "14/46 [========>.....................] - ETA: 5s - loss: 0.0863 - accuracy: 0.9821\n",
            "Training batch ke-14 dimulai pada 12:09:47.162282\n",
            "Training batch ke-14 berakhir pada 12:09:47.350219\n",
            "15/46 [========>.....................] - ETA: 5s - loss: 0.0906 - accuracy: 0.9792\n",
            "Training batch ke-15 dimulai pada 12:09:47.351421\n",
            "Training batch ke-15 berakhir pada 12:09:47.543560\n",
            "16/46 [=========>....................] - ETA: 5s - loss: 0.0925 - accuracy: 0.9785\n",
            "Training batch ke-16 dimulai pada 12:09:47.544853\n",
            "Training batch ke-16 berakhir pada 12:09:47.749126\n",
            "17/46 [==========>...................] - ETA: 5s - loss: 0.0889 - accuracy: 0.9798\n",
            "Training batch ke-17 dimulai pada 12:09:47.750324\n",
            "Training batch ke-17 berakhir pada 12:09:47.938963\n",
            "18/46 [==========>...................] - ETA: 5s - loss: 0.0881 - accuracy: 0.9809\n",
            "Training batch ke-18 dimulai pada 12:09:47.940326\n",
            "Training batch ke-18 berakhir pada 12:09:48.147271\n",
            "19/46 [===========>..................] - ETA: 5s - loss: 0.0854 - accuracy: 0.9819\n",
            "Training batch ke-19 dimulai pada 12:09:48.148621\n",
            "Training batch ke-19 berakhir pada 12:09:48.345428\n",
            "20/46 [============>.................] - ETA: 4s - loss: 0.0826 - accuracy: 0.9828\n",
            "Training batch ke-20 dimulai pada 12:09:48.346623\n",
            "Training batch ke-20 berakhir pada 12:09:48.545968\n",
            "21/46 [============>.................] - ETA: 4s - loss: 0.0835 - accuracy: 0.9821\n",
            "Training batch ke-21 dimulai pada 12:09:48.547254\n",
            "Training batch ke-21 berakhir pada 12:09:48.747987\n",
            "22/46 [=============>................] - ETA: 4s - loss: 0.0845 - accuracy: 0.9815\n",
            "Training batch ke-22 dimulai pada 12:09:48.749343\n",
            "Training batch ke-22 berakhir pada 12:09:48.938806\n",
            "23/46 [==============>...............] - ETA: 4s - loss: 0.0827 - accuracy: 0.9810\n",
            "Training batch ke-23 dimulai pada 12:09:48.939922\n",
            "Training batch ke-23 berakhir pada 12:09:49.142495\n",
            "24/46 [==============>...............] - ETA: 4s - loss: 0.0825 - accuracy: 0.9818\n",
            "Training batch ke-24 dimulai pada 12:09:49.143972\n",
            "Training batch ke-24 berakhir pada 12:09:49.330842\n",
            "25/46 [===============>..............] - ETA: 3s - loss: 0.0806 - accuracy: 0.9825\n",
            "Training batch ke-25 dimulai pada 12:09:49.332064\n",
            "Training batch ke-25 berakhir pada 12:09:49.537754\n",
            "26/46 [===============>..............] - ETA: 3s - loss: 0.0802 - accuracy: 0.9820\n",
            "Training batch ke-26 dimulai pada 12:09:49.539375\n",
            "Training batch ke-26 berakhir pada 12:09:49.732196\n",
            "27/46 [================>.............] - ETA: 3s - loss: 0.0795 - accuracy: 0.9815\n",
            "Training batch ke-27 dimulai pada 12:09:49.733334\n",
            "Training batch ke-27 berakhir pada 12:09:49.922486\n",
            "28/46 [=================>............] - ETA: 3s - loss: 0.0797 - accuracy: 0.9810\n",
            "Training batch ke-28 dimulai pada 12:09:49.924057\n",
            "Training batch ke-28 berakhir pada 12:09:50.113927\n",
            "29/46 [=================>............] - ETA: 3s - loss: 0.0794 - accuracy: 0.9817\n",
            "Training batch ke-29 dimulai pada 12:09:50.115187\n",
            "Training batch ke-29 berakhir pada 12:09:50.317605\n",
            "30/46 [==================>...........] - ETA: 3s - loss: 0.0861 - accuracy: 0.9812\n",
            "Training batch ke-30 dimulai pada 12:09:50.319257\n",
            "Training batch ke-30 berakhir pada 12:09:50.509014\n",
            "31/46 [===================>..........] - ETA: 2s - loss: 0.0858 - accuracy: 0.9808\n",
            "Training batch ke-31 dimulai pada 12:09:50.510204\n",
            "Training batch ke-31 berakhir pada 12:09:50.702110\n",
            "32/46 [===================>..........] - ETA: 2s - loss: 0.0865 - accuracy: 0.9805\n",
            "Training batch ke-32 dimulai pada 12:09:50.703356\n",
            "Training batch ke-32 berakhir pada 12:09:50.894003\n",
            "33/46 [====================>.........] - ETA: 2s - loss: 0.0846 - accuracy: 0.9811\n",
            "Training batch ke-33 dimulai pada 12:09:50.895208\n",
            "Training batch ke-33 berakhir pada 12:09:51.088113\n",
            "34/46 [=====================>........] - ETA: 2s - loss: 0.0833 - accuracy: 0.9816\n",
            "Training batch ke-34 dimulai pada 12:09:51.089372\n",
            "Training batch ke-34 berakhir pada 12:09:51.287631\n",
            "35/46 [=====================>........] - ETA: 2s - loss: 0.0826 - accuracy: 0.9821\n",
            "Training batch ke-35 dimulai pada 12:09:51.288828\n",
            "Training batch ke-35 berakhir pada 12:09:51.482666\n",
            "36/46 [======================>.......] - ETA: 1s - loss: 0.0826 - accuracy: 0.9818\n",
            "Training batch ke-36 dimulai pada 12:09:51.483828\n",
            "Training batch ke-36 berakhir pada 12:09:51.681546\n",
            "37/46 [=======================>......] - ETA: 1s - loss: 0.0822 - accuracy: 0.9814\n",
            "Training batch ke-37 dimulai pada 12:09:51.682826\n",
            "Training batch ke-37 berakhir pada 12:09:51.877742\n",
            "38/46 [=======================>......] - ETA: 1s - loss: 0.0820 - accuracy: 0.9811\n",
            "Training batch ke-38 dimulai pada 12:09:51.878995\n",
            "Training batch ke-38 berakhir pada 12:09:52.070838\n",
            "39/46 [========================>.....] - ETA: 1s - loss: 0.0820 - accuracy: 0.9808\n",
            "Training batch ke-39 dimulai pada 12:09:52.072140\n",
            "Training batch ke-39 berakhir pada 12:09:52.270629\n",
            "40/46 [=========================>....] - ETA: 1s - loss: 0.0805 - accuracy: 0.9812\n",
            "Training batch ke-40 dimulai pada 12:09:52.272111\n",
            "Training batch ke-40 berakhir pada 12:09:52.461662\n",
            "41/46 [=========================>....] - ETA: 0s - loss: 0.0796 - accuracy: 0.9817\n",
            "Training batch ke-41 dimulai pada 12:09:52.462820\n",
            "Training batch ke-41 berakhir pada 12:09:52.655853\n",
            "42/46 [==========================>...] - ETA: 0s - loss: 0.0782 - accuracy: 0.9821\n",
            "Training batch ke-42 dimulai pada 12:09:52.657146\n",
            "Training batch ke-42 berakhir pada 12:09:52.848605\n",
            "43/46 [===========================>..] - ETA: 0s - loss: 0.0770 - accuracy: 0.9826\n",
            "Training batch ke-43 dimulai pada 12:09:52.849875\n",
            "Training batch ke-43 berakhir pada 12:09:53.041762\n",
            "44/46 [===========================>..] - ETA: 0s - loss: 0.0763 - accuracy: 0.9830\n",
            "Training batch ke-44 dimulai pada 12:09:53.043356\n",
            "Training batch ke-44 berakhir pada 12:09:53.242281\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.0751 - accuracy: 0.9833\n",
            "Training batch ke-45 dimulai pada 12:09:53.243596\n",
            "Training batch ke-45 berakhir pada 12:09:53.425280\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.9837\n",
            "Evaluating batch ke-0 dimulai pada 12:09:53.445096\n",
            "\n",
            "Evaluating batch ke-0 berakhir pada 12:09:53.486057\n",
            "\n",
            "Evaluating batch ke-1 dimulai pada 12:09:53.486252\n",
            "\n",
            "Evaluating batch ke-1 berakhir pada 12:09:53.525053\n",
            "\n",
            "Evaluating batch ke-2 dimulai pada 12:09:53.525258\n",
            "\n",
            "Evaluating batch ke-2 berakhir pada 12:09:53.563629\n",
            "\n",
            "Evaluating batch ke-3 dimulai pada 12:09:53.563827\n",
            "\n",
            "Evaluating batch ke-3 berakhir pada 12:09:53.601178\n",
            "\n",
            "Evaluating batch ke-4 dimulai pada 12:09:53.601374\n",
            "\n",
            "Evaluating batch ke-4 berakhir pada 12:09:53.644995\n",
            "\n",
            "Evaluating batch ke-5 dimulai pada 12:09:53.645202\n",
            "\n",
            "Evaluating batch ke-5 berakhir pada 12:09:53.689506\n",
            "\n",
            "Evaluating batch ke-6 dimulai pada 12:09:53.689705\n",
            "\n",
            "Evaluating batch ke-6 berakhir pada 12:09:53.728013\n",
            "\n",
            "Evaluating batch ke-7 dimulai pada 12:09:53.728206\n",
            "\n",
            "Evaluating batch ke-7 berakhir pada 12:09:53.767127\n",
            "\n",
            "Evaluating batch ke-8 dimulai pada 12:09:53.767315\n",
            "\n",
            "Evaluating batch ke-8 berakhir pada 12:09:53.804218\n",
            "\n",
            "Evaluating batch ke-9 dimulai pada 12:09:53.804420\n",
            "\n",
            "Evaluating batch ke-9 berakhir pada 12:09:53.841460\n",
            "\n",
            "Evaluating batch ke-10 dimulai pada 12:09:53.841651\n",
            "\n",
            "Evaluating batch ke-10 berakhir pada 12:09:53.882814\n",
            "\n",
            "Evaluating batch ke-11 dimulai pada 12:09:53.883057\n",
            "\n",
            "Evaluating batch ke-11 berakhir pada 12:09:53.913795\n",
            "Berakhir epoch ke-6; pada waktu 12:09:53.915478\n",
            "46/46 [==============================] - 9s 203ms/step - loss: 0.0742 - accuracy: 0.9837 - val_loss: 0.2512 - val_accuracy: 0.9266\n",
            "Dimulai epoch ke-7; pada waktu 12:09:53.917859\n",
            "Epoch 8/10\n",
            "\n",
            "Training batch ke-0 dimulai pada 12:09:53.918098\n",
            "Training batch ke-0 berakhir pada 12:09:54.119441\n",
            " 1/46 [..............................] - ETA: 0s - loss: 0.0835 - accuracy: 0.9688\n",
            "Training batch ke-1 dimulai pada 12:09:54.120724\n",
            "Training batch ke-1 berakhir pada 12:09:54.326176\n",
            " 2/46 [>.............................] - ETA: 4s - loss: 0.0654 - accuracy: 0.9844\n",
            "Training batch ke-2 dimulai pada 12:09:54.327644\n",
            "Training batch ke-2 berakhir pada 12:09:54.515696\n",
            " 3/46 [>.............................] - ETA: 5s - loss: 0.0502 - accuracy: 0.9896\n",
            "Training batch ke-3 dimulai pada 12:09:54.516941\n",
            "Training batch ke-3 berakhir pada 12:09:54.705350\n",
            " 4/46 [=>............................] - ETA: 6s - loss: 0.0428 - accuracy: 0.9922\n",
            "Training batch ke-4 dimulai pada 12:09:54.706564\n",
            "Training batch ke-4 berakhir pada 12:09:54.893866\n",
            " 5/46 [==>...........................] - ETA: 6s - loss: 0.0376 - accuracy: 0.9937\n",
            "Training batch ke-5 dimulai pada 12:09:54.895356\n",
            "Training batch ke-5 berakhir pada 12:09:55.087523\n",
            " 6/46 [==>...........................] - ETA: 6s - loss: 0.0345 - accuracy: 0.9948\n",
            "Training batch ke-6 dimulai pada 12:09:55.088762\n",
            "Training batch ke-6 berakhir pada 12:09:55.285015\n",
            " 7/46 [===>..........................] - ETA: 6s - loss: 0.0320 - accuracy: 0.9955\n",
            "Training batch ke-7 dimulai pada 12:09:55.286230\n",
            "Training batch ke-7 berakhir pada 12:09:55.477274\n",
            " 8/46 [====>.........................] - ETA: 6s - loss: 0.0405 - accuracy: 0.9922\n",
            "Training batch ke-8 dimulai pada 12:09:55.478505\n",
            "Training batch ke-8 berakhir pada 12:09:55.672756\n",
            " 9/46 [====>.........................] - ETA: 6s - loss: 0.0382 - accuracy: 0.9931\n",
            "Training batch ke-9 dimulai pada 12:09:55.674609\n",
            "Training batch ke-9 berakhir pada 12:09:55.868092\n",
            "10/46 [=====>........................] - ETA: 6s - loss: 0.0363 - accuracy: 0.9937\n",
            "Training batch ke-10 dimulai pada 12:09:55.869335\n",
            "Training batch ke-10 berakhir pada 12:09:56.062008\n",
            "11/46 [======>.......................] - ETA: 6s - loss: 0.0338 - accuracy: 0.9943\n",
            "Training batch ke-11 dimulai pada 12:09:56.063225\n",
            "Training batch ke-11 berakhir pada 12:09:56.262616\n",
            "12/46 [======>.......................] - ETA: 6s - loss: 0.0318 - accuracy: 0.9948\n",
            "Training batch ke-12 dimulai pada 12:09:56.265116\n",
            "Training batch ke-12 berakhir pada 12:09:56.460303\n",
            "13/46 [=======>......................] - ETA: 5s - loss: 0.0305 - accuracy: 0.9952\n",
            "Training batch ke-13 dimulai pada 12:09:56.461509\n",
            "Training batch ke-13 berakhir pada 12:09:56.653393\n",
            "14/46 [========>.....................] - ETA: 5s - loss: 0.0312 - accuracy: 0.9933\n",
            "Training batch ke-14 dimulai pada 12:09:56.654602\n",
            "Training batch ke-14 berakhir pada 12:09:56.847553\n",
            "15/46 [========>.....................] - ETA: 5s - loss: 0.0300 - accuracy: 0.9937\n",
            "Training batch ke-15 dimulai pada 12:09:56.848679\n",
            "Training batch ke-15 berakhir pada 12:09:57.044792\n",
            "16/46 [=========>....................] - ETA: 5s - loss: 0.0307 - accuracy: 0.9941\n",
            "Training batch ke-16 dimulai pada 12:09:57.045975\n",
            "Training batch ke-16 berakhir pada 12:09:57.238338\n",
            "17/46 [==========>...................] - ETA: 5s - loss: 0.0408 - accuracy: 0.9871\n",
            "Training batch ke-17 dimulai pada 12:09:57.239583\n",
            "Training batch ke-17 berakhir pada 12:09:57.440382\n",
            "18/46 [==========>...................] - ETA: 5s - loss: 0.0550 - accuracy: 0.9844\n",
            "Training batch ke-18 dimulai pada 12:09:57.441617\n",
            "Training batch ke-18 berakhir pada 12:09:57.631325\n",
            "19/46 [===========>..................] - ETA: 4s - loss: 0.0731 - accuracy: 0.9803\n",
            "Training batch ke-19 dimulai pada 12:09:57.633144\n",
            "Training batch ke-19 berakhir pada 12:09:57.821993\n",
            "20/46 [============>.................] - ETA: 4s - loss: 0.1305 - accuracy: 0.9688\n",
            "Training batch ke-20 dimulai pada 12:09:57.823678\n",
            "Training batch ke-20 berakhir pada 12:09:58.017651\n",
            "21/46 [============>.................] - ETA: 4s - loss: 0.1760 - accuracy: 0.9568\n",
            "Training batch ke-21 dimulai pada 12:09:58.018823\n",
            "Training batch ke-21 berakhir pada 12:09:58.211617\n",
            "22/46 [=============>................] - ETA: 4s - loss: 0.1917 - accuracy: 0.9474\n",
            "Training batch ke-22 dimulai pada 12:09:58.212992\n",
            "Training batch ke-22 berakhir pada 12:09:58.411337\n",
            "23/46 [==============>...............] - ETA: 4s - loss: 0.1995 - accuracy: 0.9429\n",
            "Training batch ke-23 dimulai pada 12:09:58.412570\n",
            "Training batch ke-23 berakhir pada 12:09:58.604621\n",
            "24/46 [==============>...............] - ETA: 4s - loss: 0.2102 - accuracy: 0.9349\n",
            "Training batch ke-24 dimulai pada 12:09:58.606211\n",
            "Training batch ke-24 berakhir pada 12:09:58.804832\n",
            "25/46 [===============>..............] - ETA: 3s - loss: 0.2084 - accuracy: 0.9350\n",
            "Training batch ke-25 dimulai pada 12:09:58.806191\n",
            "Training batch ke-25 berakhir pada 12:09:58.998685\n",
            "26/46 [===============>..............] - ETA: 3s - loss: 0.2072 - accuracy: 0.9339\n",
            "Training batch ke-26 dimulai pada 12:09:58.999880\n",
            "Training batch ke-26 berakhir pada 12:09:59.191509\n",
            "27/46 [================>.............] - ETA: 3s - loss: 0.2051 - accuracy: 0.9340\n",
            "Training batch ke-27 dimulai pada 12:09:59.192750\n",
            "Training batch ke-27 berakhir pada 12:09:59.394745\n",
            "28/46 [=================>............] - ETA: 3s - loss: 0.2017 - accuracy: 0.9353\n",
            "Training batch ke-28 dimulai pada 12:09:59.395951\n",
            "Training batch ke-28 berakhir pada 12:09:59.582662\n",
            "29/46 [=================>............] - ETA: 3s - loss: 0.1996 - accuracy: 0.9375\n",
            "Training batch ke-29 dimulai pada 12:09:59.583785\n",
            "Training batch ke-29 berakhir pada 12:09:59.776150\n",
            "30/46 [==================>...........] - ETA: 3s - loss: 0.1961 - accuracy: 0.9396\n",
            "Training batch ke-30 dimulai pada 12:09:59.777340\n",
            "Training batch ke-30 berakhir pada 12:09:59.966267\n",
            "31/46 [===================>..........] - ETA: 2s - loss: 0.1956 - accuracy: 0.9405\n",
            "Training batch ke-31 dimulai pada 12:09:59.967515\n",
            "Training batch ke-31 berakhir pada 12:10:00.159291\n",
            "32/46 [===================>..........] - ETA: 2s - loss: 0.1927 - accuracy: 0.9424\n",
            "Training batch ke-32 dimulai pada 12:10:00.160520\n",
            "Training batch ke-32 berakhir pada 12:10:00.358163\n",
            "33/46 [====================>.........] - ETA: 2s - loss: 0.1922 - accuracy: 0.9422\n",
            "Training batch ke-33 dimulai pada 12:10:00.359304\n",
            "Training batch ke-33 berakhir pada 12:10:00.547289\n",
            "34/46 [=====================>........] - ETA: 2s - loss: 0.1921 - accuracy: 0.9421\n",
            "Training batch ke-34 dimulai pada 12:10:00.549186\n",
            "Training batch ke-34 berakhir pada 12:10:00.736948\n",
            "35/46 [=====================>........] - ETA: 2s - loss: 0.1903 - accuracy: 0.9429\n",
            "Training batch ke-35 dimulai pada 12:10:00.738187\n",
            "Training batch ke-35 berakhir pada 12:10:00.928213\n",
            "36/46 [======================>.......] - ETA: 1s - loss: 0.1901 - accuracy: 0.9418\n",
            "Training batch ke-36 dimulai pada 12:10:00.929454\n",
            "Training batch ke-36 berakhir pada 12:10:01.118936\n",
            "37/46 [=======================>......] - ETA: 1s - loss: 0.1883 - accuracy: 0.9417\n",
            "Training batch ke-37 dimulai pada 12:10:01.120170\n",
            "Training batch ke-37 berakhir pada 12:10:01.313443\n",
            "38/46 [=======================>......] - ETA: 1s - loss: 0.1856 - accuracy: 0.9424\n",
            "Training batch ke-38 dimulai pada 12:10:01.314628\n",
            "Training batch ke-38 berakhir pada 12:10:01.512656\n",
            "39/46 [========================>.....] - ETA: 1s - loss: 0.1862 - accuracy: 0.9407\n",
            "Training batch ke-39 dimulai pada 12:10:01.513833\n",
            "Training batch ke-39 berakhir pada 12:10:01.701515\n",
            "40/46 [=========================>....] - ETA: 1s - loss: 0.1881 - accuracy: 0.9391\n",
            "Training batch ke-40 dimulai pada 12:10:01.702704\n",
            "Training batch ke-40 berakhir pada 12:10:01.893929\n",
            "41/46 [=========================>....] - ETA: 0s - loss: 0.1850 - accuracy: 0.9398\n",
            "Training batch ke-41 dimulai pada 12:10:01.895168\n",
            "Training batch ke-41 berakhir pada 12:10:02.088644\n",
            "42/46 [==========================>...] - ETA: 0s - loss: 0.1823 - accuracy: 0.9405\n",
            "Training batch ke-42 dimulai pada 12:10:02.090442\n",
            "Training batch ke-42 berakhir pada 12:10:02.283560\n",
            "43/46 [===========================>..] - ETA: 0s - loss: 0.1796 - accuracy: 0.9419\n",
            "Training batch ke-43 dimulai pada 12:10:02.284872\n",
            "Training batch ke-43 berakhir pada 12:10:02.486658\n",
            "44/46 [===========================>..] - ETA: 0s - loss: 0.1759 - accuracy: 0.9432\n",
            "Training batch ke-44 dimulai pada 12:10:02.487944\n",
            "Training batch ke-44 berakhir pada 12:10:02.674920\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.1744 - accuracy: 0.9431\n",
            "Training batch ke-45 dimulai pada 12:10:02.676318\n",
            "Training batch ke-45 berakhir pada 12:10:02.859377\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.1749 - accuracy: 0.9422\n",
            "Evaluating batch ke-0 dimulai pada 12:10:02.878876\n",
            "\n",
            "Evaluating batch ke-0 berakhir pada 12:10:02.918988\n",
            "\n",
            "Evaluating batch ke-1 dimulai pada 12:10:02.919187\n",
            "\n",
            "Evaluating batch ke-1 berakhir pada 12:10:02.956612\n",
            "\n",
            "Evaluating batch ke-2 dimulai pada 12:10:02.956812\n",
            "\n",
            "Evaluating batch ke-2 berakhir pada 12:10:02.996042\n",
            "\n",
            "Evaluating batch ke-3 dimulai pada 12:10:02.996298\n",
            "\n",
            "Evaluating batch ke-3 berakhir pada 12:10:03.036272\n",
            "\n",
            "Evaluating batch ke-4 dimulai pada 12:10:03.036479\n",
            "\n",
            "Evaluating batch ke-4 berakhir pada 12:10:03.077564\n",
            "\n",
            "Evaluating batch ke-5 dimulai pada 12:10:03.077767\n",
            "\n",
            "Evaluating batch ke-5 berakhir pada 12:10:03.120313\n",
            "\n",
            "Evaluating batch ke-6 dimulai pada 12:10:03.120522\n",
            "\n",
            "Evaluating batch ke-6 berakhir pada 12:10:03.158307\n",
            "\n",
            "Evaluating batch ke-7 dimulai pada 12:10:03.158504\n",
            "\n",
            "Evaluating batch ke-7 berakhir pada 12:10:03.195675\n",
            "\n",
            "Evaluating batch ke-8 dimulai pada 12:10:03.195870\n",
            "\n",
            "Evaluating batch ke-8 berakhir pada 12:10:03.233273\n",
            "\n",
            "Evaluating batch ke-9 dimulai pada 12:10:03.233472\n",
            "\n",
            "Evaluating batch ke-9 berakhir pada 12:10:03.271748\n",
            "\n",
            "Evaluating batch ke-10 dimulai pada 12:10:03.271972\n",
            "\n",
            "Evaluating batch ke-10 berakhir pada 12:10:03.314038\n",
            "\n",
            "Evaluating batch ke-11 dimulai pada 12:10:03.314230\n",
            "\n",
            "Evaluating batch ke-11 berakhir pada 12:10:03.344296\n",
            "Berakhir epoch ke-7; pada waktu 12:10:03.346147\n",
            "46/46 [==============================] - 9s 201ms/step - loss: 0.1749 - accuracy: 0.9422 - val_loss: 0.3358 - val_accuracy: 0.8777\n",
            "Dimulai epoch ke-8; pada waktu 12:10:03.348361\n",
            "Epoch 9/10\n",
            "\n",
            "Training batch ke-0 dimulai pada 12:10:03.348587\n",
            "Training batch ke-0 berakhir pada 12:10:03.549630\n",
            " 1/46 [..............................] - ETA: 0s - loss: 0.0444 - accuracy: 0.9688\n",
            "Training batch ke-1 dimulai pada 12:10:03.551309\n",
            "Training batch ke-1 berakhir pada 12:10:03.741348\n",
            " 2/46 [>.............................] - ETA: 4s - loss: 0.0705 - accuracy: 0.9688\n",
            "Training batch ke-2 dimulai pada 12:10:03.742562\n",
            "Training batch ke-2 berakhir pada 12:10:03.935295\n",
            " 3/46 [>.............................] - ETA: 5s - loss: 0.0642 - accuracy: 0.9688\n",
            "Training batch ke-3 dimulai pada 12:10:03.936537\n",
            "Training batch ke-3 berakhir pada 12:10:04.131509\n",
            " 4/46 [=>............................] - ETA: 6s - loss: 0.0520 - accuracy: 0.9766\n",
            "Training batch ke-4 dimulai pada 12:10:04.132760\n",
            "Training batch ke-4 berakhir pada 12:10:04.327823\n",
            " 5/46 [==>...........................] - ETA: 6s - loss: 0.0775 - accuracy: 0.9688\n",
            "Training batch ke-5 dimulai pada 12:10:04.329123\n",
            "Training batch ke-5 berakhir pada 12:10:04.521832\n",
            " 6/46 [==>...........................] - ETA: 6s - loss: 0.0679 - accuracy: 0.9740\n",
            "Training batch ke-6 dimulai pada 12:10:04.525614\n",
            "Training batch ke-6 berakhir pada 12:10:04.713451\n",
            " 7/46 [===>..........................] - ETA: 6s - loss: 0.0622 - accuracy: 0.9777\n",
            "Training batch ke-7 dimulai pada 12:10:04.714693\n",
            "Training batch ke-7 berakhir pada 12:10:04.903798\n",
            " 8/46 [====>.........................] - ETA: 6s - loss: 0.0576 - accuracy: 0.9805\n",
            "Training batch ke-8 dimulai pada 12:10:04.905040\n",
            "Training batch ke-8 berakhir pada 12:10:05.097628\n",
            " 9/46 [====>.........................] - ETA: 6s - loss: 0.0562 - accuracy: 0.9826\n",
            "Training batch ke-9 dimulai pada 12:10:05.098885\n",
            "Training batch ke-9 berakhir pada 12:10:05.288443\n",
            "10/46 [=====>........................] - ETA: 6s - loss: 0.0600 - accuracy: 0.9812\n",
            "Training batch ke-10 dimulai pada 12:10:05.289626\n",
            "Training batch ke-10 berakhir pada 12:10:05.491743\n",
            "11/46 [======>.......................] - ETA: 6s - loss: 0.0595 - accuracy: 0.9830\n",
            "Training batch ke-11 dimulai pada 12:10:05.492974\n",
            "Training batch ke-11 berakhir pada 12:10:05.683381\n",
            "12/46 [======>.......................] - ETA: 6s - loss: 0.0559 - accuracy: 0.9844\n",
            "Training batch ke-12 dimulai pada 12:10:05.686101\n",
            "Training batch ke-12 berakhir pada 12:10:05.877476\n",
            "13/46 [=======>......................] - ETA: 5s - loss: 0.0597 - accuracy: 0.9832\n",
            "Training batch ke-13 dimulai pada 12:10:05.878715\n",
            "Training batch ke-13 berakhir pada 12:10:06.075622\n",
            "14/46 [========>.....................] - ETA: 5s - loss: 0.0571 - accuracy: 0.9844\n",
            "Training batch ke-14 dimulai pada 12:10:06.076962\n",
            "Training batch ke-14 berakhir pada 12:10:06.268704\n",
            "15/46 [========>.....................] - ETA: 5s - loss: 0.0549 - accuracy: 0.9854\n",
            "Training batch ke-15 dimulai pada 12:10:06.270371\n",
            "Training batch ke-15 berakhir pada 12:10:06.467530\n",
            "16/46 [=========>....................] - ETA: 5s - loss: 0.0560 - accuracy: 0.9863\n",
            "Training batch ke-16 dimulai pada 12:10:06.468745\n",
            "Training batch ke-16 berakhir pada 12:10:06.657562\n",
            "17/46 [==========>...................] - ETA: 5s - loss: 0.0594 - accuracy: 0.9853\n",
            "Training batch ke-17 dimulai pada 12:10:06.659104\n",
            "Training batch ke-17 berakhir pada 12:10:06.850957\n",
            "18/46 [==========>...................] - ETA: 5s - loss: 0.0582 - accuracy: 0.9861\n",
            "Training batch ke-18 dimulai pada 12:10:06.852168\n",
            "Training batch ke-18 berakhir pada 12:10:07.040006\n",
            "19/46 [===========>..................] - ETA: 4s - loss: 0.0592 - accuracy: 0.9868\n",
            "Training batch ke-19 dimulai pada 12:10:07.041285\n",
            "Training batch ke-19 berakhir pada 12:10:07.232709\n",
            "20/46 [============>.................] - ETA: 4s - loss: 0.0579 - accuracy: 0.9875\n",
            "Training batch ke-20 dimulai pada 12:10:07.234064\n",
            "Training batch ke-20 berakhir pada 12:10:07.424074\n",
            "21/46 [============>.................] - ETA: 4s - loss: 0.0569 - accuracy: 0.9881\n",
            "Training batch ke-21 dimulai pada 12:10:07.425198\n",
            "Training batch ke-21 berakhir pada 12:10:07.630786\n",
            "22/46 [=============>................] - ETA: 4s - loss: 0.0574 - accuracy: 0.9872\n",
            "Training batch ke-22 dimulai pada 12:10:07.632320\n",
            "Training batch ke-22 berakhir pada 12:10:07.828677\n",
            "23/46 [==============>...............] - ETA: 4s - loss: 0.0558 - accuracy: 0.9878\n",
            "Training batch ke-23 dimulai pada 12:10:07.830104\n",
            "Training batch ke-23 berakhir pada 12:10:08.029072\n",
            "24/46 [==============>...............] - ETA: 4s - loss: 0.0568 - accuracy: 0.9857\n",
            "Training batch ke-24 dimulai pada 12:10:08.030344\n",
            "Training batch ke-24 berakhir pada 12:10:08.232373\n",
            "25/46 [===============>..............] - ETA: 3s - loss: 0.0572 - accuracy: 0.9850\n",
            "Training batch ke-25 dimulai pada 12:10:08.233985\n",
            "Training batch ke-25 berakhir pada 12:10:08.430250\n",
            "26/46 [===============>..............] - ETA: 3s - loss: 0.0562 - accuracy: 0.9856\n",
            "Training batch ke-26 dimulai pada 12:10:08.431504\n",
            "Training batch ke-26 berakhir pada 12:10:08.641449\n",
            "27/46 [================>.............] - ETA: 3s - loss: 0.0580 - accuracy: 0.9838\n",
            "Training batch ke-27 dimulai pada 12:10:08.642671\n",
            "Training batch ke-27 berakhir pada 12:10:08.846802\n",
            "28/46 [=================>............] - ETA: 3s - loss: 0.0575 - accuracy: 0.9844\n",
            "Training batch ke-28 dimulai pada 12:10:08.849375\n",
            "Training batch ke-28 berakhir pada 12:10:09.054973\n",
            "29/46 [=================>............] - ETA: 3s - loss: 0.0563 - accuracy: 0.9849\n",
            "Training batch ke-29 dimulai pada 12:10:09.056182\n",
            "Training batch ke-29 berakhir pada 12:10:09.255509\n",
            "30/46 [==================>...........] - ETA: 3s - loss: 0.0558 - accuracy: 0.9854\n",
            "Training batch ke-30 dimulai pada 12:10:09.256879\n",
            "Training batch ke-30 berakhir pada 12:10:09.459554\n",
            "31/46 [===================>..........] - ETA: 2s - loss: 0.0580 - accuracy: 0.9849\n",
            "Training batch ke-31 dimulai pada 12:10:09.460844\n",
            "Training batch ke-31 berakhir pada 12:10:09.674512\n",
            "32/46 [===================>..........] - ETA: 2s - loss: 0.0570 - accuracy: 0.9854\n",
            "Training batch ke-32 dimulai pada 12:10:09.676629\n",
            "Training batch ke-32 berakhir pada 12:10:09.871185\n",
            "33/46 [====================>.........] - ETA: 2s - loss: 0.0625 - accuracy: 0.9839\n",
            "Training batch ke-33 dimulai pada 12:10:09.872689\n",
            "Training batch ke-33 berakhir pada 12:10:10.072674\n",
            "34/46 [=====================>........] - ETA: 2s - loss: 0.0616 - accuracy: 0.9844\n",
            "Training batch ke-34 dimulai pada 12:10:10.073941\n",
            "Training batch ke-34 berakhir pada 12:10:10.276449\n",
            "35/46 [=====================>........] - ETA: 2s - loss: 0.0605 - accuracy: 0.9848\n",
            "Training batch ke-35 dimulai pada 12:10:10.278077\n",
            "Training batch ke-35 berakhir pada 12:10:10.476838\n",
            "36/46 [======================>.......] - ETA: 1s - loss: 0.0601 - accuracy: 0.9852\n",
            "Training batch ke-36 dimulai pada 12:10:10.478207\n",
            "Training batch ke-36 berakhir pada 12:10:10.698482\n",
            "37/46 [=======================>......] - ETA: 1s - loss: 0.0595 - accuracy: 0.9856\n",
            "Training batch ke-37 dimulai pada 12:10:10.699722\n",
            "Training batch ke-37 berakhir pada 12:10:10.914144\n",
            "38/46 [=======================>......] - ETA: 1s - loss: 0.0605 - accuracy: 0.9852\n",
            "Training batch ke-38 dimulai pada 12:10:10.915410\n",
            "Training batch ke-38 berakhir pada 12:10:11.113404\n",
            "39/46 [========================>.....] - ETA: 1s - loss: 0.0598 - accuracy: 0.9856\n",
            "Training batch ke-39 dimulai pada 12:10:11.114723\n",
            "Training batch ke-39 berakhir pada 12:10:11.312052\n",
            "40/46 [=========================>....] - ETA: 1s - loss: 0.0588 - accuracy: 0.9859\n",
            "Training batch ke-40 dimulai pada 12:10:11.313358\n",
            "Training batch ke-40 berakhir pada 12:10:11.508352\n",
            "41/46 [=========================>....] - ETA: 0s - loss: 0.0578 - accuracy: 0.9863\n",
            "Training batch ke-41 dimulai pada 12:10:11.509658\n",
            "Training batch ke-41 berakhir pada 12:10:11.720775\n",
            "42/46 [==========================>...] - ETA: 0s - loss: 0.0570 - accuracy: 0.9866\n",
            "Training batch ke-42 dimulai pada 12:10:11.722612\n",
            "Training batch ke-42 berakhir pada 12:10:11.918050\n",
            "43/46 [===========================>..] - ETA: 0s - loss: 0.0575 - accuracy: 0.9862\n",
            "Training batch ke-43 dimulai pada 12:10:11.919915\n",
            "Training batch ke-43 berakhir pada 12:10:12.127428\n",
            "44/46 [===========================>..] - ETA: 0s - loss: 0.0572 - accuracy: 0.9865\n",
            "Training batch ke-44 dimulai pada 12:10:12.129382\n",
            "Training batch ke-44 berakhir pada 12:10:12.346883\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.0575 - accuracy: 0.9861\n",
            "Training batch ke-45 dimulai pada 12:10:12.348752\n",
            "Training batch ke-45 berakhir pada 12:10:12.542794\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9857\n",
            "Evaluating batch ke-0 dimulai pada 12:10:12.566853\n",
            "\n",
            "Evaluating batch ke-0 berakhir pada 12:10:12.611826\n",
            "\n",
            "Evaluating batch ke-1 dimulai pada 12:10:12.612074\n",
            "\n",
            "Evaluating batch ke-1 berakhir pada 12:10:12.653849\n",
            "\n",
            "Evaluating batch ke-2 dimulai pada 12:10:12.654103\n",
            "\n",
            "Evaluating batch ke-2 berakhir pada 12:10:12.694212\n",
            "\n",
            "Evaluating batch ke-3 dimulai pada 12:10:12.694423\n",
            "\n",
            "Evaluating batch ke-3 berakhir pada 12:10:12.734381\n",
            "\n",
            "Evaluating batch ke-4 dimulai pada 12:10:12.734592\n",
            "\n",
            "Evaluating batch ke-4 berakhir pada 12:10:12.779704\n",
            "\n",
            "Evaluating batch ke-5 dimulai pada 12:10:12.779978\n",
            "\n",
            "Evaluating batch ke-5 berakhir pada 12:10:12.819668\n",
            "\n",
            "Evaluating batch ke-6 dimulai pada 12:10:12.819875\n",
            "\n",
            "Evaluating batch ke-6 berakhir pada 12:10:12.862959\n",
            "\n",
            "Evaluating batch ke-7 dimulai pada 12:10:12.863183\n",
            "\n",
            "Evaluating batch ke-7 berakhir pada 12:10:12.905224\n",
            "\n",
            "Evaluating batch ke-8 dimulai pada 12:10:12.905431\n",
            "\n",
            "Evaluating batch ke-8 berakhir pada 12:10:12.947297\n",
            "\n",
            "Evaluating batch ke-9 dimulai pada 12:10:12.947519\n",
            "\n",
            "Evaluating batch ke-9 berakhir pada 12:10:12.991412\n",
            "\n",
            "Evaluating batch ke-10 dimulai pada 12:10:12.991616\n",
            "\n",
            "Evaluating batch ke-10 berakhir pada 12:10:13.034696\n",
            "\n",
            "Evaluating batch ke-11 dimulai pada 12:10:13.035197\n",
            "\n",
            "Evaluating batch ke-11 berakhir pada 12:10:13.063494\n",
            "Berakhir epoch ke-8; pada waktu 12:10:13.065285\n",
            "46/46 [==============================] - 10s 207ms/step - loss: 0.0583 - accuracy: 0.9857 - val_loss: 0.3035 - val_accuracy: 0.9130\n",
            "Dimulai epoch ke-9; pada waktu 12:10:13.068247\n",
            "Epoch 10/10\n",
            "\n",
            "Training batch ke-0 dimulai pada 12:10:13.068454\n",
            "Training batch ke-0 berakhir pada 12:10:13.268013\n",
            " 1/46 [..............................] - ETA: 0s - loss: 0.0175 - accuracy: 1.0000\n",
            "Training batch ke-1 dimulai pada 12:10:13.269923\n",
            "Training batch ke-1 berakhir pada 12:10:13.472872\n",
            " 2/46 [>.............................] - ETA: 4s - loss: 0.0134 - accuracy: 1.0000\n",
            "Training batch ke-2 dimulai pada 12:10:13.474256\n",
            "Training batch ke-2 berakhir pada 12:10:13.691990\n",
            " 3/46 [>.............................] - ETA: 6s - loss: 0.0167 - accuracy: 1.0000\n",
            "Training batch ke-3 dimulai pada 12:10:13.693325\n",
            "Training batch ke-3 berakhir pada 12:10:13.892768\n",
            " 4/46 [=>............................] - ETA: 6s - loss: 0.0696 - accuracy: 0.9844\n",
            "Training batch ke-4 dimulai pada 12:10:13.895019\n",
            "Training batch ke-4 berakhir pada 12:10:14.100849\n",
            " 5/46 [==>...........................] - ETA: 6s - loss: 0.0661 - accuracy: 0.9812\n",
            "Training batch ke-5 dimulai pada 12:10:14.102530\n",
            "Training batch ke-5 berakhir pada 12:10:14.292729\n",
            " 6/46 [==>...........................] - ETA: 6s - loss: 0.0589 - accuracy: 0.9844\n",
            "Training batch ke-6 dimulai pada 12:10:14.293879\n",
            "Training batch ke-6 berakhir pada 12:10:14.492086\n",
            " 7/46 [===>..........................] - ETA: 6s - loss: 0.0531 - accuracy: 0.9866\n",
            "Training batch ke-7 dimulai pada 12:10:14.493386\n",
            "Training batch ke-7 berakhir pada 12:10:14.702090\n",
            " 8/46 [====>.........................] - ETA: 6s - loss: 0.0483 - accuracy: 0.9883\n",
            "Training batch ke-8 dimulai pada 12:10:14.703302\n",
            "Training batch ke-8 berakhir pada 12:10:14.893091\n",
            " 9/46 [====>.........................] - ETA: 6s - loss: 0.0461 - accuracy: 0.9896\n",
            "Training batch ke-9 dimulai pada 12:10:14.894302\n",
            "Training batch ke-9 berakhir pada 12:10:15.087997\n",
            "10/46 [=====>........................] - ETA: 6s - loss: 0.0460 - accuracy: 0.9906\n",
            "Training batch ke-10 dimulai pada 12:10:15.089387\n",
            "Training batch ke-10 berakhir pada 12:10:15.283644\n",
            "11/46 [======>.......................] - ETA: 6s - loss: 0.0504 - accuracy: 0.9886\n",
            "Training batch ke-11 dimulai pada 12:10:15.285291\n",
            "Training batch ke-11 berakhir pada 12:10:15.477809\n",
            "12/46 [======>.......................] - ETA: 6s - loss: 0.0470 - accuracy: 0.9896\n",
            "Training batch ke-12 dimulai pada 12:10:15.479307\n",
            "Training batch ke-12 berakhir pada 12:10:15.691320\n",
            "13/46 [=======>......................] - ETA: 6s - loss: 0.0450 - accuracy: 0.9904\n",
            "Training batch ke-13 dimulai pada 12:10:15.692822\n",
            "Training batch ke-13 berakhir pada 12:10:15.885039\n",
            "14/46 [========>.....................] - ETA: 5s - loss: 0.0431 - accuracy: 0.9911\n",
            "Training batch ke-14 dimulai pada 12:10:15.886677\n",
            "Training batch ke-14 berakhir pada 12:10:16.082514\n",
            "15/46 [========>.....................] - ETA: 5s - loss: 0.0443 - accuracy: 0.9896\n",
            "Training batch ke-15 dimulai pada 12:10:16.083754\n",
            "Training batch ke-15 berakhir pada 12:10:16.273521\n",
            "16/46 [=========>....................] - ETA: 5s - loss: 0.0425 - accuracy: 0.9902\n",
            "Training batch ke-16 dimulai pada 12:10:16.275062\n",
            "Training batch ke-16 berakhir pada 12:10:16.467736\n",
            "17/46 [==========>...................] - ETA: 5s - loss: 0.0429 - accuracy: 0.9908\n",
            "Training batch ke-17 dimulai pada 12:10:16.469036\n",
            "Training batch ke-17 berakhir pada 12:10:16.668797\n",
            "18/46 [==========>...................] - ETA: 5s - loss: 0.0416 - accuracy: 0.9913\n",
            "Training batch ke-18 dimulai pada 12:10:16.670287\n",
            "Training batch ke-18 berakhir pada 12:10:16.857637\n",
            "19/46 [===========>..................] - ETA: 5s - loss: 0.0410 - accuracy: 0.9918\n",
            "Training batch ke-19 dimulai pada 12:10:16.858875\n",
            "Training batch ke-19 berakhir pada 12:10:17.058461\n",
            "20/46 [============>.................] - ETA: 4s - loss: 0.0396 - accuracy: 0.9922\n",
            "Training batch ke-20 dimulai pada 12:10:17.059770\n",
            "Training batch ke-20 berakhir pada 12:10:17.248165\n",
            "21/46 [============>.................] - ETA: 4s - loss: 0.0408 - accuracy: 0.9911\n",
            "Training batch ke-21 dimulai pada 12:10:17.249749\n",
            "Training batch ke-21 berakhir pada 12:10:17.443644\n",
            "22/46 [=============>................] - ETA: 4s - loss: 0.0413 - accuracy: 0.9915\n",
            "Training batch ke-22 dimulai pada 12:10:17.444943\n",
            "Training batch ke-22 berakhir pada 12:10:17.638043\n",
            "23/46 [==============>...............] - ETA: 4s - loss: 0.0407 - accuracy: 0.9918\n",
            "Training batch ke-23 dimulai pada 12:10:17.639348\n",
            "Training batch ke-23 berakhir pada 12:10:17.846177\n",
            "24/46 [==============>...............] - ETA: 4s - loss: 0.0400 - accuracy: 0.9922\n",
            "Training batch ke-24 dimulai pada 12:10:17.847452\n",
            "Training batch ke-24 berakhir pada 12:10:18.043323\n",
            "25/46 [===============>..............] - ETA: 4s - loss: 0.0410 - accuracy: 0.9912\n",
            "Training batch ke-25 dimulai pada 12:10:18.044514\n",
            "Training batch ke-25 berakhir pada 12:10:18.235168\n",
            "26/46 [===============>..............] - ETA: 3s - loss: 0.0401 - accuracy: 0.9916\n",
            "Training batch ke-26 dimulai pada 12:10:18.236392\n",
            "Training batch ke-26 berakhir pada 12:10:18.427071\n",
            "27/46 [================>.............] - ETA: 3s - loss: 0.0393 - accuracy: 0.9919\n",
            "Training batch ke-27 dimulai pada 12:10:18.428283\n",
            "Training batch ke-27 berakhir pada 12:10:18.621267\n",
            "28/46 [=================>............] - ETA: 3s - loss: 0.0396 - accuracy: 0.9911\n",
            "Training batch ke-28 dimulai pada 12:10:18.622848\n",
            "Training batch ke-28 berakhir pada 12:10:18.818809\n",
            "29/46 [=================>............] - ETA: 3s - loss: 0.0386 - accuracy: 0.9914\n",
            "Training batch ke-29 dimulai pada 12:10:18.820082\n",
            "Training batch ke-29 berakhir pada 12:10:19.013483\n",
            "30/46 [==================>...........] - ETA: 3s - loss: 0.0380 - accuracy: 0.9917\n",
            "Training batch ke-30 dimulai pada 12:10:19.014718\n",
            "Training batch ke-30 berakhir pada 12:10:19.206114\n",
            "31/46 [===================>..........] - ETA: 2s - loss: 0.0382 - accuracy: 0.9919\n",
            "Training batch ke-31 dimulai pada 12:10:19.207341\n",
            "Training batch ke-31 berakhir pada 12:10:19.401247\n",
            "32/46 [===================>..........] - ETA: 2s - loss: 0.0373 - accuracy: 0.9922\n",
            "Training batch ke-32 dimulai pada 12:10:19.402756\n",
            "Training batch ke-32 berakhir pada 12:10:19.606378\n",
            "33/46 [====================>.........] - ETA: 2s - loss: 0.0366 - accuracy: 0.9924\n",
            "Training batch ke-33 dimulai pada 12:10:19.607596\n",
            "Training batch ke-33 berakhir pada 12:10:19.806136\n",
            "34/46 [=====================>........] - ETA: 2s - loss: 0.0374 - accuracy: 0.9917\n",
            "Training batch ke-34 dimulai pada 12:10:19.807316\n",
            "Training batch ke-34 berakhir pada 12:10:19.998175\n",
            "35/46 [=====================>........] - ETA: 2s - loss: 0.0371 - accuracy: 0.9920\n",
            "Training batch ke-35 dimulai pada 12:10:19.999491\n",
            "Training batch ke-35 berakhir pada 12:10:20.193734\n",
            "36/46 [======================>.......] - ETA: 1s - loss: 0.0365 - accuracy: 0.9922\n",
            "Training batch ke-36 dimulai pada 12:10:20.195329\n",
            "Training batch ke-36 berakhir pada 12:10:20.389811\n",
            "37/46 [=======================>......] - ETA: 1s - loss: 0.0358 - accuracy: 0.9924\n",
            "Training batch ke-37 dimulai pada 12:10:20.391090\n",
            "Training batch ke-37 berakhir pada 12:10:20.586974\n",
            "38/46 [=======================>......] - ETA: 1s - loss: 0.0359 - accuracy: 0.9926\n",
            "Training batch ke-38 dimulai pada 12:10:20.588233\n",
            "Training batch ke-38 berakhir pada 12:10:20.791195\n",
            "39/46 [========================>.....] - ETA: 1s - loss: 0.0354 - accuracy: 0.9928\n",
            "Training batch ke-39 dimulai pada 12:10:20.792703\n",
            "Training batch ke-39 berakhir pada 12:10:20.981826\n",
            "40/46 [=========================>....] - ETA: 1s - loss: 0.0347 - accuracy: 0.9930\n",
            "Training batch ke-40 dimulai pada 12:10:20.982951\n",
            "Training batch ke-40 berakhir pada 12:10:21.174819\n",
            "41/46 [=========================>....] - ETA: 0s - loss: 0.0341 - accuracy: 0.9931\n",
            "Training batch ke-41 dimulai pada 12:10:21.176103\n",
            "Training batch ke-41 berakhir pada 12:10:21.366601\n",
            "42/46 [==========================>...] - ETA: 0s - loss: 0.0336 - accuracy: 0.9933\n",
            "Training batch ke-42 dimulai pada 12:10:21.367886\n",
            "Training batch ke-42 berakhir pada 12:10:21.556534\n",
            "43/46 [===========================>..] - ETA: 0s - loss: 0.0330 - accuracy: 0.9935\n",
            "Training batch ke-43 dimulai pada 12:10:21.558188\n",
            "Training batch ke-43 berakhir pada 12:10:21.748181\n",
            "44/46 [===========================>..] - ETA: 0s - loss: 0.0347 - accuracy: 0.9929\n",
            "Training batch ke-44 dimulai pada 12:10:21.749343\n",
            "Training batch ke-44 berakhir pada 12:10:21.957283\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.0361 - accuracy: 0.9924\n",
            "Training batch ke-45 dimulai pada 12:10:21.958401\n",
            "Training batch ke-45 berakhir pada 12:10:22.145385\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 0.9918\n",
            "Evaluating batch ke-0 dimulai pada 12:10:22.165358\n",
            "\n",
            "Evaluating batch ke-0 berakhir pada 12:10:22.207496\n",
            "\n",
            "Evaluating batch ke-1 dimulai pada 12:10:22.207693\n",
            "\n",
            "Evaluating batch ke-1 berakhir pada 12:10:22.246814\n",
            "\n",
            "Evaluating batch ke-2 dimulai pada 12:10:22.247275\n",
            "\n",
            "Evaluating batch ke-2 berakhir pada 12:10:22.286638\n",
            "\n",
            "Evaluating batch ke-3 dimulai pada 12:10:22.286837\n",
            "\n",
            "Evaluating batch ke-3 berakhir pada 12:10:22.324100\n",
            "\n",
            "Evaluating batch ke-4 dimulai pada 12:10:22.324294\n",
            "\n",
            "Evaluating batch ke-4 berakhir pada 12:10:22.362043\n",
            "\n",
            "Evaluating batch ke-5 dimulai pada 12:10:22.362236\n",
            "\n",
            "Evaluating batch ke-5 berakhir pada 12:10:22.403544\n",
            "\n",
            "Evaluating batch ke-6 dimulai pada 12:10:22.403743\n",
            "\n",
            "Evaluating batch ke-6 berakhir pada 12:10:22.440996\n",
            "\n",
            "Evaluating batch ke-7 dimulai pada 12:10:22.441184\n",
            "\n",
            "Evaluating batch ke-7 berakhir pada 12:10:22.478322\n",
            "\n",
            "Evaluating batch ke-8 dimulai pada 12:10:22.478509\n",
            "\n",
            "Evaluating batch ke-8 berakhir pada 12:10:22.515773\n",
            "\n",
            "Evaluating batch ke-9 dimulai pada 12:10:22.516014\n",
            "\n",
            "Evaluating batch ke-9 berakhir pada 12:10:22.552790\n",
            "\n",
            "Evaluating batch ke-10 dimulai pada 12:10:22.553374\n",
            "\n",
            "Evaluating batch ke-10 berakhir pada 12:10:22.590388\n",
            "\n",
            "Evaluating batch ke-11 dimulai pada 12:10:22.590586\n",
            "\n",
            "Evaluating batch ke-11 berakhir pada 12:10:22.619252\n",
            "Berakhir epoch ke-9; pada waktu 12:10:22.620754\n",
            "46/46 [==============================] - 9s 203ms/step - loss: 0.0364 - accuracy: 0.9918 - val_loss: 0.2380 - val_accuracy: 0.9239\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4xhw5x5bYgp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "798e4d2c-cf27-4d32-c9a0-8e45cab1f7df"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "training_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epoch_count = range(1, len(training_loss) + 1)\n",
        "\n",
        "plt.plot(epoch_count, training_loss, 'r-')\n",
        "plt.plot(epoch_count, val_loss, 'b-')\n",
        "plt.legend(['Training Loss', 'Validation Loss'])\n",
        "plt.title('Training dan Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV7Rugw9dDcz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "f8ef33c6-bc66-4ea7-f540-250ae856dd56"
      },
      "source": [
        "training_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "epoch_count = range(1, len(training_loss) + 1)\n",
        "\n",
        "plt.plot(epoch_count, training_accuracy, 'r-')\n",
        "plt.plot(epoch_count, val_accuracy, 'b-')\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'])\n",
        "plt.title('Training dan Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgIMnp_iyHFl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78c878ad-eba0-4ff1-aaaf-b0a78de9d9a6"
      },
      "source": [
        "# buat ekspor model\n",
        "# 1. Impor model terlebih dahulu\n",
        "saving_path = (\"/content/mymodel/\") #path penyimpanan model\n",
        "tf.saved_model.save(model, saving_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/mymodel/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLVqqygpzno-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "80ba2ced-d147-4427-edc9-8021ff2a2e9e"
      },
      "source": [
        "!pip install \"tensorflow>=1.7.0\"\n",
        "!pip install tensorflowjs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow>=1.7.0 in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.7.0) (0.3.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.7.0) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.7.0) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.7.0) (3.3.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.7.0) (1.4.1)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.7.0) (2.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.7.0) (2.3.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.7.0) (1.1.2)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.7.0) (2.10.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.7.0) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.7.0) (3.12.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.7.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.7.0) (1.12.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.7.0) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.7.0) (0.35.1)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.7.0) (1.18.5)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.7.0) (1.31.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.7.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.7.0) (0.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.7.0) (49.6.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.7.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.7.0) (1.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.7.0) (3.2.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.7.0) (1.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=1.7.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=1.7.0) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=1.7.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=1.7.0) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=1.7.0) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=1.7.0) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=1.7.0) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=1.7.0) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=1.7.0) (1.7.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=1.7.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=1.7.0) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=1.7.0) (3.1.0)\n",
            "Collecting tensorflowjs\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/4c/79739ad8652e4f0372ddfa272d4fa3bfb0497460bc319e3758e907586540/tensorflowjs-2.3.0-py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 2.9MB/s \n",
            "\u001b[?25hCollecting tensorflow-hub==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/0e/a91780d07592b1abf9c91344ce459472cc19db3b67fdf3a61dca6ebb2f5c/tensorflow_hub-0.7.0-py2.py3-none-any.whl (89kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.15.0)\n",
            "Collecting PyInquirer==1.0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/fb/4c/434b7c454010a284b49d6f1d446fe8dc5960415613d8c0225b9e2efb6724/PyInquirer-1.0.3.tar.gz\n",
            "Collecting tensorflow-cpu<3,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/f6/b2996d65fb72200b1455a776d38915760b097ad1fa8c1c177a8cccbff07a/tensorflow_cpu-2.3.0-cp36-cp36m-manylinux2010_x86_64.whl (137.3MB)\n",
            "\u001b[K     |████████████████████████████████| 137.3MB 75kB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.10.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub==0.7.0->tensorflowjs) (3.12.4)\n",
            "Collecting prompt_toolkit==1.0.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/3d/b25d35a9f0d381dd1c02d8e04b37c353caaaff4bc32150328eeebe4931f5/prompt_toolkit-1.0.14-py3-none-any.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 46.1MB/s \n",
            "\u001b[?25hCollecting Pygments>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/68/106af3ae51daf807e9cdcba6a90e518954eb8b70341cee52995540a53ead/Pygments-2.6.1-py3-none-any.whl (914kB)\n",
            "\u001b[K     |████████████████████████████████| 921kB 41.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex>=2016.11.21 in /usr/local/lib/python3.6/dist-packages (from PyInquirer==1.0.3->tensorflowjs) (2019.12.20)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (0.3.3)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.4.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.31.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (2.3.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (2.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (0.35.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow-hub==0.7.0->tensorflowjs) (49.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt_toolkit==1.0.14->PyInquirer==1.0.3->tensorflowjs) (0.2.5)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (0.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (3.2.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (3.0.4)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.7.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
            "Building wheels for collected packages: PyInquirer\n",
            "  Building wheel for PyInquirer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyInquirer: filename=PyInquirer-1.0.3-cp36-none-any.whl size=32852 sha256=0f820de5ff7c2a17d8c7a77310da65e543d91962ccb2ec1905af4559e0fb9531\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/6c/b1/3e4b0e8daf42a92883c7641c0ea8ffb62e0490ebed2faa55ad\n",
            "Successfully built PyInquirer\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-hub, prompt-toolkit, Pygments, PyInquirer, tensorflow-cpu, tensorflowjs\n",
            "  Found existing installation: tensorflow-hub 0.9.0\n",
            "    Uninstalling tensorflow-hub-0.9.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.9.0\n",
            "  Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "  Found existing installation: Pygments 2.1.3\n",
            "    Uninstalling Pygments-2.1.3:\n",
            "      Successfully uninstalled Pygments-2.1.3\n",
            "Successfully installed PyInquirer-1.0.3 Pygments-2.6.1 prompt-toolkit-1.0.14 tensorflow-cpu-2.3.0 tensorflow-hub-0.7.0 tensorflowjs-2.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "prompt_toolkit",
                  "pygments",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3ymPrbF2KM8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8deb56ff-bdb5-451b-e773-3bff47acf300"
      },
      "source": [
        "!saved_model_cli show --dir /content/mymodel \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The given SavedModel contains the following tag-sets:\n",
            "'serve'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIZkawgoy1Vt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "outputId": "6a9eb21b-1a77-4f88-f02c-858911104a2f"
      },
      "source": [
        "!tensorflowjs_converter \\\n",
        "    --input_format tf_saved_model \\\n",
        "    --output_node_names ‘MobilenetV1/Predictions/Reshape_1‘ \\\n",
        "    /content/mymodel/ \\\n",
        "    /content/modeltfjs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-09-03 12:05:14.478336: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2020-09-03 12:05:14.482845: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz\n",
            "2020-09-03 12:05:14.483126: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d34d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-09-03 12:05:14.483166: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-09-03 12:05:19.013323: I tensorflow/core/grappler/devices.cc:78] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
            "2020-09-03 12:05:19.013522: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
            "2020-09-03 12:05:19.032858: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize\n",
            "2020-09-03 12:05:19.032945: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: Graph size after: 477 nodes (463), 639 edges (625), time = 8.539ms.\n",
            "2020-09-03 12:05:19.032960: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.219ms.\n",
            "2020-09-03 12:05:19.433129: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize\n",
            "2020-09-03 12:05:19.433196: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   debug_stripper: debug_stripper did nothing. time = 0.025ms.\n",
            "2020-09-03 12:05:19.433208: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   model_pruner: Graph size after: 296 nodes (-84), 358 edges (-84), time = 1.887ms.\n",
            "2020-09-03 12:05:19.433222: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   constant_folding: Graph size after: 296 nodes (0), 358 edges (0), time = 6.18ms.\n",
            "2020-09-03 12:05:19.433233: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   arithmetic_optimizer: Graph size after: 296 nodes (0), 358 edges (0), time = 4.078ms.\n",
            "2020-09-03 12:05:19.433245: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   dependency_optimizer: Graph size after: 268 nodes (-28), 312 edges (-46), time = 1.83ms.\n",
            "2020-09-03 12:05:19.433258: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   model_pruner: Graph size after: 268 nodes (0), 312 edges (0), time = 0.914ms.\n",
            "2020-09-03 12:05:19.433278: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   constant_folding: Graph size after: 268 nodes (0), 312 edges (0), time = 4.758ms.\n",
            "2020-09-03 12:05:19.433287: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   arithmetic_optimizer: Graph size after: 268 nodes (0), 312 edges (0), time = 3.69ms.\n",
            "2020-09-03 12:05:19.433300: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   dependency_optimizer: Graph size after: 268 nodes (0), 312 edges (0), time = 1.471ms.\n",
            "2020-09-03 12:05:19.433312: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   debug_stripper: debug_stripper did nothing. time = 0.113ms.\n",
            "2020-09-03 12:05:19.433325: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   model_pruner: Graph size after: 268 nodes (0), 312 edges (0), time = 0.782ms.\n",
            "2020-09-03 12:05:19.433337: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   constant_folding: Graph size after: 268 nodes (0), 312 edges (0), time = 4.205ms.\n",
            "2020-09-03 12:05:19.433350: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   arithmetic_optimizer: Graph size after: 268 nodes (0), 312 edges (0), time = 4.064ms.\n",
            "2020-09-03 12:05:19.433362: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   dependency_optimizer: Graph size after: 268 nodes (0), 312 edges (0), time = 1.54ms.\n",
            "2020-09-03 12:05:19.433374: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   model_pruner: Graph size after: 268 nodes (0), 312 edges (0), time = 0.908ms.\n",
            "2020-09-03 12:05:19.433386: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   constant_folding: Graph size after: 268 nodes (0), 312 edges (0), time = 4.471ms.\n",
            "2020-09-03 12:05:19.433399: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   arithmetic_optimizer: Graph size after: 268 nodes (0), 312 edges (0), time = 4.044ms.\n",
            "2020-09-03 12:05:19.433411: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   dependency_optimizer: Graph size after: 268 nodes (0), 312 edges (0), time = 1.545ms.\n",
            "2020-09-03 12:05:19.474133: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize\n",
            "2020-09-03 12:05:19.474196: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   remapper: Graph size after: 265 nodes (-3), 309 edges (-3), time = 0.818ms.\n",
            "2020-09-03 12:05:19.474208: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   constant_folding: Graph size after: 265 nodes (0), 309 edges (0), time = 5.173ms.\n",
            "2020-09-03 12:05:19.474220: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   arithmetic_optimizer: Graph size after: 265 nodes (0), 309 edges (0), time = 3.858ms.\n",
            "2020-09-03 12:05:19.474233: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   dependency_optimizer: Graph size after: 265 nodes (0), 309 edges (0), time = 1.58ms.\n",
            "2020-09-03 12:05:19.474243: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   remapper: Graph size after: 265 nodes (0), 309 edges (0), time = 0.685ms.\n",
            "2020-09-03 12:05:19.474256: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   constant_folding: Graph size after: 265 nodes (0), 309 edges (0), time = 4.361ms.\n",
            "2020-09-03 12:05:19.474276: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   arithmetic_optimizer: Graph size after: 265 nodes (0), 309 edges (0), time = 4.015ms.\n",
            "2020-09-03 12:05:19.474285: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   dependency_optimizer: Graph size after: 265 nodes (0), 309 edges (0), time = 1.629ms.\n",
            "Writing weight file /content/modeltfjs/model.json...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88ZfgFK60zgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "word2index = tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARFPnlDI1Fah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "with open('word2index.json', 'w') as fp:\n",
        "    json.dump(word2index, fp)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}